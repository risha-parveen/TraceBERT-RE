issue_id,commit_id,p_x,l_x,issue_desc,issue_comments,summary,diff,files,created_at,closed_at,commit_time
10,672575a8e3f414ce9ffa1f47b1e18b13d13fb9eb,0.0005894320784136,0,"See # 22 . Given SQL statement by the wrapper , produce a QEP wrapped in a data format ( classically a tree graph , but simpler format like list probably works here too ) that can be efficiently examined in semantic analysis . QEPs can be fetched in roughly following way :",Basic QEP parser module,Merge pull request # 44 from Project-C-SQL/feat/improve-qeps,"assert len ( qep.root.rfindval ( `` Node Type '' , `` Bitmap Heap Scan '' ) ) == 1 return self.find ( pred , recursive=True ) `` `` '' Finds nodes with the given key and value . assert qep.root.findval ( `` Alias '' , `` users '' ) == [ qep.plan ] assert qep.root.findval ( `` Actual Rows '' , 4 ) == [ qep.plan ] self._ref = bool ( conn ) assert qep.root.findval ( `` Actual Rows '' , 2 ) == [ qep.plan ] : param key : the key to search for To install all dependencies and the application , type ` poetry install ` . After installation , if the Python scripts folder is in your PATH , you should be able to invoke ` main.main ( ) ` with ` pg4n ` . : param key : the index of the child node to get qep = parser ( `` select * from comments where id = 1 '' ) password=getenv ( `` PGPASSWORD '' ) , Having PostgreSQL running on port 5432 , do ` poetry run pytest ` ( or , if on port x , just do ` PGPORT=x poetry run pytest ` ) . `` `` '' Test that the QEP find method works as expected . '' '' '' : returns : the child node at the given index `` `` '' Test that the QEP rfind ( recursive find ) method works as expected . '' '' '' return map ( QEPNode , self._node.get ( `` Plans '' , [ ] ) ) list ( chain.from_iterable ( x.find ( pr , True ) for x in iter ( self ) ) ) | -- -- -- -- -- -- | -- -- -- -- -- -- -- - | -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - | return self._node.get ( `` Plans '' , [ ] ) `` `` '' Finds nodes matching the predicate . assert qep.root.findval ( `` Alias '' , `` comments '' ) == [ qep.plan ] | ` PGDBNAME ` | ` test_database ` | Database name . | return self.find ( lambda x : x.get ( key ) == val , recursive ) : param val : the value to search for if recursive : def rfindval ( self , key : str , val : object ) - > list [ node ] : stmt = f '' explain ( format json , analyze , verbose ) { stmt.strip ( ) .rstrip ( ' ; ' ) } ; '' | Variable | Default value | Description | assert len ( qep.root.rfindval ( `` Node Type '' , `` BitmapOr '' ) ) == 2 | ` PGPASSWORD ` | | Password , in case password authentication is used . | qep = parser ( `` select * from stories where id = 1 '' ) assert qep.root.findval ( `` Alias '' , `` stories '' ) == [ qep.plan ] return map ( QEPNode , self._node [ `` Plans '' ] ) : param pr : a function that takes a node and returns True if it matches qep = parser ( `` select * from stories where id = 1 or id = 2 '' ) `` `` '' Get the child node at the given index . '' '' '' def rfind ( self , pred : Callable [ [ node ] , bool ] ) - > list [ node ] : assert qep.root.findval ( `` Relation Name '' , `` stories '' ) == [ qep.plan ] qep = parser ( `` select * from users where id = 1 '' ) | ` PGPORT ` | ` 5432 ` | Port to an active PostgreSQL instance . | this+children To install all dependencies and the application , type ` poetry install ` . After installation , if the Python scripts folder is in your PATH , you should be able to invoke ` main.main ( ) ` with ` pg4n ` . : param node_ : the node to wrap '' '' '' return self.find ( pr ) + \ self._conn.commit ( ) qep = parser ( `` select * from users '' ) | ` PGUSER ` | ` postgres ` | The user that will be used to manage the test database . | recursive=False ) - > list [ node ] : return self._node [ `` Plans '' ] with self._conn.cursor ( ) as cur : `` `` '' Finds nodes with the given key and value , recursively . : param pred : a function that takes a node and returns True if it matches : returns : a list of matching nodes Having PostgreSQL running on port 5432 , do ` poetry run pytest ` . qep = parser ( `` select * from users where id = 1 or id = 2 '' ) return self.findval ( key , val , recursive=True ) `` `` '' Find nodes matching the predicate . '' '' '' qep = parser ( `` select * from comments where id = 1 or id = 2 '' ) # use constraint_exclusion to avoid unnecessary index scans assert len ( qep.root.rfindval ( `` Node Type '' , `` Bitmap Index Scan '' ) ) == 4 def test_qep_find ( parser : qepparser.QEPParser ) : qep = parser ( `` select * from comments '' ) self._ref = not not conn def find ( self , pred : Callable [ [ node ] , bool ] ) - > list [ node ] : For example , if PostgreSQL is on port 5433 , just do ` PGPORT=5433 poetry run pytest ` ( Bash syntax ) . assert qep.root.findval ( `` Node Type '' , `` Seq Scan '' ) == [ qep.plan ] assert qep.root.findval ( `` Actual Rows '' , 1 ) == [ qep.plan ] def test_gep_rfind ( parser : qepparser.QEPParser ) : To get a similar instance as with GitHub Actions workflow : < br > : param recursive : if True , search recursively , otherwise only search `` `` '' Create a new QEPNode . qep = parser ( `` select * from stories '' ) def findval ( self , key : str , val : object , recursive=False ) - > list [ node ] : return list ( filter ( pr , chain ( ( self._node , ) , self.plans ) ) ) `` `` '' Get the child node at the given index . def find ( self , pr : Callable [ [ node ] , bool ] , dbname=getenv ( `` PGDBNAME '' , `` test_database '' ) ) return list ( filter ( pred , self._node [ `` Plans '' ] ) ) You may need to provide environment variables that match your config : from itertools import chain stmt.strip ( ) .rstrip ( ' ; ' ) + `` ; '' password=getenv ( `` PGPASSWORD '' , `` postgres '' ) ) `` `` '' cur.execute ( `` set constraint_exclusion = on ; '' ) stmt = `` explain ( format json , analyze , verbose ) '' + \ | ` PGHOST ` | ` 127.0.0.1 ` | Hostname of the PostgreSQL server . | assert qep.root.findval ( `` Relation Name '' , `` users '' ) == [ qep.plan ] assert qep.root.findval ( `` Node Type '' , `` Index Scan '' ) == [ qep.plan ] assert qep.root.findval ( `` Relation Name '' , `` comments '' ) == [ qep.plan ] To get a similar PostgreSQL instance as with GitHub Actions workflow : < br > `` `` '' Finds nodes matching the predicate , recursively .","['README.md', 'src/pg4n/qepparser.py', 'src/pg4n/test/test_qepparser.py']",2022-09-23 11:52:46+00:00,2022-10-11 14:32:31+00:00,2022-11-05 13:28:47+02:00
10,bbd831ee1f05324f62486eca5ace30ed845111a7,4.104824984096922e-05,0,"See # 22 . Given SQL statement by the wrapper , produce a QEP wrapped in a data format ( classically a tree graph , but simpler format like list probably works here too ) that can be efficiently examined in semantic analysis . QEPs can be fetched in roughly following way :",Basic QEP parser module,Merge pull request # 77 from Project-C-SQL/feat/errfmt,"warning_msg = `` Warning : Possible use of '= ' instead of % for wildcard pattern [ pg4n : :EqWildcard ] '' formatter = ErrorFormatter ( warning , warning_name ) msg_header = f '' Warning : Comparison between different domains ( { domain1 } , { domain2 } ) [ pg4n : :CmpDomains ] \n '' warning_name = `` SumDistinct '' self.warning_msg = self.warning_msg + msg_header + underlined_query formatter = ErrorFormatter ( warning , warning_name ) from . qepparser import QEPAnalysis warning_name = `` EqWildcard '' warning_name = `` SubquerySelect '' ) self.warning_msg = formatter.format ( ) warning_name = `` StrangeHaving '' VT100_RESET = `` \x1b [ 0m '' warning = `` DISTINCT in SUM or AVG '' warning_name = `` CmpDomains '' warning_name = `` SurplusSemicolons '' warning_name = `` InnerOrderBy '' warning = `` ORDER BY in a subquery '' warning_msg = `` Warning : ORDER BY in a subquery [ pg4n : :InnerOrderBy ] '' warning_name = `` ImpliedExpression '' warning_msg = `` Warning : DISTINCT in SUM or AVG [ pg4n : :SumDistinct ] '' self.warning_name : str = warning_name warning_header = `` Warning : No column in subquery SELECT references its tables [ pg4n : :SubquerySelect ] \n '' warning_msg = formatter.format ( ) self.underlined_query : Optional [ str ] = underlined_query warning = `` Too many semicolons '' assert ( warning = `` No column in subquery SELECT references its tables '' formatter = ErrorFormatter ( warning , warning_name , underlined_query ) warning_msg.find ( warning ) ! = -1 self.warning_msg : str = warning_msg warning_msg += formatter.format ( ) warning = `` HAVING without GROUP BY '' from typing import Optional underlined_query : Optional [ str ] = None , assert warning_msg.find ( warning ) ! = -1 and warning_msg.find ( warning_name ) ! = -1 def __init__ ( warning = `` Too many parentheses '' warning_name = `` SurplusParentheses '' from .qepparser import QEPAnalysis FROM customers ) : class ErrorFormatter : and warning_msg.find ( warning_name ) ! = -1 warning = f '' Comparison between different domains ( { domain1 } , { domain2 } ) '' Returns a formatted error message . return base_msg warning = `` Found impossible comparison due to column/table constraints '' def test_format ( ) : self , formatter = ErrorFormatter ( warning , warning_name , underlined_query ) from .errfmt import ErrorFormatter underlined_query = f '' '' '' SELECT * from .. errfmt import ErrorFormatter warning_name : str , base_msg = f '' Warning : { self.warning_msg } [ pg4n : : { self.warning_name } ] '' warning_msg = `` Warning : HAVING without GROUP BY [ pg4n : :StrangeHaving ] '' if self.underlined_query : warning_msg = `` Warning : Found impossible comparison due to column/table constraints [ pg4n : :ImpliedExpression ] '' warning = `` Possible use of '= ' instead of LIKE for wildcard pattern '' def format ( self ) - > str : `` `` '' and warning_msg.find ( underlined_query ) ! = -1 VT100_UNDERLINE = `` \x1b [ 4m '' warning_msg : str , warning_msg += warning_header + underlined_query { VT100_UNDERLINE } WHERE type ' C ' { VT100_RESET } = 1 OR 100 = 100 ; '' '' '' return base_msg + f '' \n { self.underlined_query } '' warning_msg = formatter.format ( )","['src/pg4n/cmp_domain_checker.py', 'src/pg4n/eq_wildcard_checker.py', 'src/pg4n/errfmt.py', 'src/pg4n/implied_expression_checker.py', 'src/pg4n/strange_having_checker.py', 'src/pg4n/subquery_orderby_checker.py', 'src/pg4n/subquery_select_checker.py', 'src/pg4n/sum_distinct_checker.py', 'src/pg4n/test/test_errfmt.py']",2022-09-23 11:52:46+00:00,2022-10-11 14:32:31+00:00,2022-11-21 12:21:55+02:00
10,3d6dec83450eb47b7c1c89380c7d32be851a2780,4.39509421994444e-05,0,"See # 22 . Given SQL statement by the wrapper , produce a QEP wrapped in a data format ( classically a tree graph , but simpler format like list probably works here too ) that can be efficiently examined in semantic analysis . QEPs can be fetched in roughly following way :",Basic QEP parser module,Merge pull request # 97 from Project-C-SQL/fix/qepparser-crash,"if self.qep_analysis is None : return QEPAnalysis ( res [ 0 ] [ 0 ] [ 0 ] ) with self._conn.cursor ( ) as cur : raise ValueError ( f '' Expected 1 row , got { n } '' ) if ( n : = len ( res ) ) ! = 1 : return QEPAnalysis ( res [ 0 ] [ 0 ] [ 0 ] ) if ( n : = len ( res [ 0 ] ) ) ! = 1 : try : if ( t : = type ( res [ 0 ] [ 0 ] [ 0 ] ) ) ! = dict : self._conn.commit ( ) cur.execute ( `` set constraint_exclusion = on ; '' ) raise ValueError ( f '' Expected 1 item in column , got { n } '' ) if ( t : = type ( res [ 0 ] [ 0 ] [ 0 ] ) ) ! = dict : if qep_analysis_with_constraint_exclusion is None : cur.execute ( stmt , * args , * * kwargs ) if ( n : = len ( res ) ) ! = 1 : with self._conn.cursor ( ) as cur : if ( n : = len ( res [ 0 ] [ 0 ] ) ) ! = 1 : cur.execute ( `` set constraint_exclusion = off ; '' ) cur.execute ( `` set constraint_exclusion = on ; '' ) if ( n : = len ( res [ 0 ] [ 0 ] ) ) ! = 1 : if qep_analysis_without_constraint_exclusion is None : raise ValueError ( f '' Expected 1 row , got { n } '' ) raise ValueError ( f '' Expected dict in column , got { t } '' ) self._conn.rollback ( ) self._conn.commit ( ) self._conn.rollback ( ) cur.execute ( `` set constraint_exclusion = off ; '' ) cur.execute ( stmt , * args , * * kwargs ) except Exception as e : try : res = cur.fetchall ( ) raise ValueError ( f '' Expected 1 column , got { n } '' ) return None res = cur.fetchall ( ) raise ValueError ( f '' Expected 1 item in column , got { n } '' ) raise ValueError ( f '' Expected 1 column , got { n } '' ) stmt = `` explain ( format json , analyze , verbose ) '' + \ stmt = `` explain ( format json , analyze , verbose ) `` + \ if ( n : = len ( res [ 0 ] ) ) ! = 1 : except psycopg.Error as e : raise ValueError ( f '' Expected dict in column , got { t } '' )","['src/pg4n/implied_expression_checker.py', 'src/pg4n/qepparser.py', 'src/pg4n/subquery_order_by_checker.py']",2022-09-23 11:52:46+00:00,2022-10-11 14:32:31+00:00,2022-12-16 13:05:50+02:00
11,aebf426ab3350d922e78442db19398914f4610aa,3.8566504372283816e-05,0,Integrate python-sqlparse for turning the SQL statement string into a data structure for efficient semantic analysis .,Basic SQL parser,Merge pull request # 53 from Project-C-SQL/feat/semantic-router,"results = [ res_list [ 3 ] [ : :-1 ] , pg_name : str res_list [ 2 ] [ : :-1 ] print_msg = self.pg4n_message.replace ( `` \n '' , `` \r\n '' ) force router . analysis_result = CmpDomainChecker ( sanitized_sql , columns ) .check ( ) wrapper ) . self.pg_user = conninfo_res [ 3 ] with psycopg.connect ( `` host= '' + self.pg_host results = [ res_list [ 3 ] [ : :-1 ] , def start ( self ) - > None : Literal , Word , \ self.pg_host : str = pg_host # ^either stops after dbname or includes \x1b [ ? 2004l ... conn_info = PsqlConnInfo ( tok_pre_user : ParserElement = \ print_msg + `` \r\n\r\n '' return `` '' # No semantic errors found def get ( self ) - > ( str , str , str , str , str ) : way we can avoid writing a command-line argument parser . '' '' '' sem_router.run_analysis , def __init__ ( self , psql_args : str ) : Word ( nums ) ) .get ( ) def test_parse_new_prompt_and_rest ( ) - > None : psqlparser.PsqlParser ( ) ) message in return . self.pg4n_message + `` \r\n\r\n '' from .psqlwrapper import PsqlWrapper self.tok_pre_host + self.tok_host + \ class SemanticRouter : self.pg_pass = `` '' return analysis_result reduce ( lambda x , y : x + y , sys.argv [ 1 : ] , `` '' ) # concat arguments def _replace_prompt ( self , prompt : bytes ) - > bytes : def new_psqlwrapper ( ) : ( StringEnd ( ) | ( Literal ( `` ? [ \x1b '' ) + \ sanitized_sql : exp.Expression = sql_parser.parse_one ( sql_query ) try : Literal ( `` \ '' via socket in \ '' '' ) def main ( ) - > None : from . import psqlwrapper `` user= '' + self.pg_user def run_analysis ( self , sql_query : str ) - > str : self.tok_pre_database + self.tok_database + \ running all the modules on all queries . For now , it is dumb brute : returns : an insightful message that might include vt100-compatible \ `` `` '' Run analysis modules on SQL query string and get an insightful \ self.pg_name ) tok_pre_database : ParserElement = \ from .. import psqlwrapper self.pg_host = conninfo_res [ 5 ] identbodychars , nums Literal ( `` \ '' at port \ '' '' ) `` dbname= '' + self.pg_name except ParseException as e : from typing import Optional lambda x : `` Test '' , res_list [ 2 ] [ : :-1 ] sem_router = SemanticRouter ( * conn_info ) # asterisk unpacks the 5-tuple res_list [ 1 ] [ : :-1 ] self.pg_user : str = pg_user pg_port : str , ] Literal ( `` \ '' on host \ '' '' ) | \ from pyparsing import \ `` `` '' Analyze given SQL queries via a plethora of analysis modules . '' '' '' elif len ( res_list ) == 2 : # stops right after database name columns : list [ Column ] = sql_parser.get_query_columns ( sanitized_sql ) from sqlglot import exp tok_user : ParserElement = \ psql = psqlwrapper.PsqlWrapper ( `` '' , name . '' '' '' ... + StringEnd ( ) self.pg_name : str = pg_name self.tok_pre_user + self.tok_user + \ analysis_result : Optional [ str ] = None from functools import reduce from .psqlconninfo import PsqlConnInfo results = [ `` , `` `` '' from .cmp_domain_checker import CmpDomainChecker print ( `` Fatal error : psql connection info could not be parsed\n '' def test_parse_new_prompt_and_rest ( ) : def main ( ) : Word ( identbodychars + `` / . '' ) def test_ofilter ( ) : res_list [ 0 ] [ : :-1 ] if len ( res_list ) == 4 : # includes \x1b [ ? 2004l p = psqlparser.PsqlParser ( ) from .. import psqlparser import pexpect to initialize connection info . '' '' '' match_psql_conninfo.parse_string ( conninfo_str ) .as_list ( ) pg_pass : str , tok_port : ParserElement = \ psql = PsqlWrapper ( sys.argv [ 1 ] .encode ( `` utf-8 '' ) , print ( e.explain ( ) ) psql = PsqlWrapper ( `` '' , print ( f '' { os.path.basename ( sys.executable ) } \ self.pg_port , def _replace_prompt ( self , prompt : bytes ) : ParseException , ParserElement , \ pexpect_conninfo.expect ( pexpect.EOF ) psqlparser.PsqlParser ( ) ) def new_psqlwrapper ( ) - > PsqlWrapper : ... + StringEnd ( ) ) ) conninfo_str = bytes.decode ( pexpect_conninfo.before ) self.tok_end self.tok_pre_port + self.tok_port + \ psql : psqlwrapper.PsqlWrapper = new_psqlwrapper ( ) Word ( self.prompt_chars ) + \ from .psqlparser import PsqlParser control codes . \n is newline ( carriage return \r will be added by \ self.pg_user , from .. psqlparser import PsqlParser pg_host : str , tok_pre_port : ParserElement = \ pass match_psql_conninfo : ParserElement = \ `` `` '' Get 5-tuple that has the PostgreSQL host , port , user , pass , and db \ conninfo_res = \ Semantic router ( some day ) implements basic heuristics to avoid PsqlParser ( ) ) tok_host : ParserElement = \ PsqlParser ( ) ) sql_parser : SqlParser = SqlParser ( conn ) : param sql_query : is a single well-formed query to run analytics on . def test_ofilter ( ) - > None : from .semanticrouter import SemanticRouter tok_database : ParserElement = \ def test_parse_new_prompt ( ) : `` `` '' Get PostgreSQL server address , port , database name , and user via \ tok_end : ParserElement = \ psql = psqlwrapper.PsqlWrapper ( sys.argv [ 1 ] .encode ( `` utf-8 '' ) , import psycopg def start ( self ) : main.py [ psql arguments ] < database name > '' ) `` password= '' + self.pg_pass ) as conn : if analysis_result is not None : Literal ( `` You are connected to database \ '' '' ) res_list [ 1 ] [ : :-1 ] def test_parse_magical_return ( ) - > None : from . import psqlparser tok_pre_host : ParserElement = \ p = PsqlParser ( ) def __init__ ( self , self.pg_port : str = pg_port Literal ( `` \ '' as user \ '' '' ) return ( self.pg_host , Word ( identbodychars ) `` `` '' Use psql child process with exact same command-line arguments \ `` `` '' Initialize Postgres connection with given paramaters . '' '' '' from .sqlparser import SqlParser , Column ] pg_user : str , def test_parse_magical_return ( ) : lambda x : `` Helpful message '' , res_list [ 0 ] [ : :-1 ] self.pg_pass : str = pg_pass def test_parse_last_found_stmt ( ) : psql : PsqlWrapper = new_psqlwrapper ( ) self.pg_port = conninfo_res [ 7 ] pexpect_conninfo = pexpect.spawn ( `` psql -c \ '' \\conninfo\ '' `` + psql_args ) Word ( self.prompt_chars ) + Literal ( `` ? [ \x1b '' ) + \ class PsqlConnInfo : Literal ( `` \ '' . '' ) print ( f '' { os.path.basename ( sys.executable ) } main.py < database name > '' ) from .. psqlwrapper import PsqlWrapper def test_parse_last_found_stmt ( ) - > None : def test_parse_new_prompt ( ) - > None : e.explain ( ) ) self.pg_pass , self.pg_name = conninfo_res [ 1 ] lambda x : `` Test '' , psql by supplying same arguments as the original psql process . This \ `` port= '' + self.pg_port # analysis modules ) : # Comparing different domains","['src/pg4n/main.py', 'src/pg4n/psqlconninfo.py', 'src/pg4n/psqlparser.py', 'src/pg4n/psqlwrapper.py', 'src/pg4n/semanticrouter.py', 'src/pg4n/test/test_psqlparser.py', 'src/pg4n/test/test_psqlwrapper.py']",2022-09-23 11:55:17+00:00,2022-10-26 09:21:21+00:00,2022-11-07 20:09:02+02:00
12,6c5e663747462817aa670b59addb191b618c5eb9,0.0004883952206,0,"Turn an SQL statement , its results , and a QEP into an insightful message to the user . # 6 # 7 # 8 # 9",Basic semantic analysis,Merge pull request # 29 from Project-C-SQL/feat/qep-parser,"`` `` '' Represents the result of EXPLAIN ANALYZE . '' '' '' `` Scan Direction '' : str , assert qep.plan [ `` Node Type '' ] == `` Seq Scan '' return QEPNode ( self._node [ `` Plans '' ] [ key ] ) `` Triggers '' : list [ str ] , for copy-and-pasting `` Plans '' : List [ `` node '' ] , create table comments ( node = TypedDict ( `` Plan '' , { assert qep.plan [ `` Actual Rows '' ] == 4 `` Plan Rows '' : int , assert qep.plan [ `` Relation Name '' ] == `` comments '' return self ( stmt , * args , * * kwargs ) `` Parent Relationship '' : str , story_id integer references stories ( id ) on delete cascade , import qepparser conn : connection = psycopg2.connect ( * * kwargs ) * * kwargs : Keyword arguments to pass to cursor.execute ( ) . postgresql_in_docker = factories.postgresql_noproc ( self._ref = not not conn qep = parser ( `` select * from users where id = 1 and id = 2 '' ) def plan ( self ) - > node : assert qep.plan [ `` Relation Name '' ] == `` stories '' raise ValueError ( f '' Expected dict in column , got { t } '' ) # TODO : break into variants discriminated by Node Type return self._node return qepparser.QEPParser ( conn=postgresql ) * text=auto def load_database ( * * kwargs ) : import psycopg2 `` `` '' A dict of the query execution plan 's properties . '' '' '' def __call__ ( self , stmt : str , * args , * * kwargs ) - > QEPAnalysis : return list ( filter ( pred , self._node [ `` Plans '' ] ) ) qep = parser ( `` select * from stories where id = 1 '' ) def __init__ ( self , qep_ : qep ) : return self._node.__str__ ( ) def __init__ ( self , node_ : node ) : qep = parser ( `` select * from stories where id = 1 and id = 2 '' ) return map ( QEPNode , self._node [ `` Plans '' ] ) password=getenv ( `` POSTGRES_PASSWORD '' , `` postgres '' ) ) qep = parser ( `` select * from stories where id = 1 or id = 2 '' ) if ( n : = len ( res [ 0 ] ) ) ! = 1 : self._node = node_ insert into comments ( story_id , user_id , comment ) values ( 2 , 1 , 'comment3 ' ) ; insert into comments ( story_id , user_id , comment ) values ( 1 , 2 , 'comment2 ' ) ; qep = parser ( `` select * from users where id = 1 '' ) def __len__ ( self ) - > int : return self._node [ `` Plans '' ] `` Actual Total Time '' : float , `` `` '' A dict of the root node 's properties . '' '' '' `` `` '' The root node of the query execution plan . '' '' '' qep = parser ( `` select * from users '' ) assert qep.plan [ `` Actual Rows '' ] == 2 `` Filter '' : str , return self._qep.__repr__ ( ) `` `` '' Iterate over child nodes . '' '' '' if ( n : = len ( res [ 0 ] [ 0 ] ) ) ! = 1 : import pytest with self._conn.cursor ( ) as cur : insert into stories ( name ) values ( 'story1 ' ) ; # are available for each node type assert qep.plan [ `` Node Type '' ] == `` Index Scan '' if ( t : = type ( res [ 0 ] [ 0 ] [ 0 ] ) ) ! = dict : if not self._ref : `` Alias '' : str , qep = parser ( `` select * from comments where id = 1 and id = 2 '' ) def plans ( self ) - > list [ node ] : `` Planning Time '' : float , insert into comments ( story_id , user_id , comment ) values ( 1 , 1 , 'comment1 ' ) ; return self._qep def __del__ ( self ) : `` Execution Time '' : float , create table stories ( id serial primary key , name varchar ) ; self._qep = qep_ return QEPNode ( self._qep [ `` Plan '' ] ) assert qep.plan [ `` Relation Name '' ] == `` users '' class QEPAnalysis : qep = TypedDict ( `` QEP '' , { qep = parser ( `` select * from comments '' ) `` `` '' Test that the QEP structure is as expected . '' '' '' self._conn.close ( ) raise ValueError ( f '' Expected 1 row , got { n } '' ) assert qep.root [ 0 ] .plan [ `` Actual Rows '' ] == 0 assert qep.plan [ `` Node Type '' ] == `` Bitmap Heap Scan '' qep = parser ( `` select * from stories '' ) `` `` '' Get the number of child nodes . '' '' '' insert into comments ( story_id , user_id , comment ) values ( 2 , 2 , 'comment4 ' ) ; def parser ( postgresql : connection ) : Executes a query and returns the query execution plan as a dictionary . `` `` '' } ) cur.execute ( `` '' '' drop table if exists users ; return QEPAnalysis ( res [ 0 ] [ 0 ] [ 0 ] ) create table users ( id serial primary key , name varchar ) ; demonstrates relational data assert qep.root [ 0 ] .plan [ `` Alias '' ] == `` users '' Parameters : id serial primary key , def parse ( self , stmt : str , * args , * * kwargs ) - > QEPAnalysis : `` Plan '' : node , from typing import Callable , Iterable , List , TypedDict qep = parser ( `` select * from comments where id = 1 '' ) `` Total Cost '' : float , res = cur.fetchall ( ) `` Index Name '' : str , assert qep.root [ 0 ] .plan [ `` Node Type '' ] == `` Index Scan '' `` `` '' Find nodes matching the predicate . '' '' '' `` Total Runtime '' : float , `` `` '' Get the child node at the given index . '' '' '' def root ( self ) - > QEPNode : return len ( self._node [ `` Plans '' ] ) assert qep.plan [ `` Alias '' ] == `` users '' class QEPParser : def test_qep_structure ( parser : qepparser.QEPParser ) : from os import getenv conn.commit ( ) assert qep.plan [ `` Alias '' ] == `` stories '' cur.execute ( stmt , * args , * * kwargs ) def qep ( self ) - > qep : drop table if exists stories ; comment varchar ) ; insert into users ( name ) values ( 'user1 ' ) ; if ( n : = len ( res ) ) ! = 1 : `` Startup Cost '' : float , '' 'Alias for __call__ '' ' `` Relation Name '' : str , raise ValueError ( f '' Expected 1 item in column , got { n } '' ) return self._qep.__str__ ( ) `` Index Cond '' : str , assert qep.root [ 0 ] .plan [ `` Alias '' ] == `` stories '' def __init__ ( self , * args , conn=None , * * kwargs ) : `` Actual Loops '' : int , self._conn.rollback ( ) # right now , the interface is n't safe to use because it 's not clear what fields def __iter__ ( self ) - > Iterable [ `` QEPNode '' ] : def __str__ ( self ) : stmt = f '' explain ( format json , analyze , verbose ) { stmt.strip ( ) .rstrip ( ' ; ' ) } ; '' A dictionary representing the query execution plan . drop table if exists comments ; `` `` '' A node in a query execution plan . '' '' '' `` `` '' A list of the node 's children . '' '' '' `` `` '' A dict of the node 's properties . '' '' '' with conn.cursor ( ) as cur : `` `` '' ) `` Actual Rows '' : int , populate with sample data assert qep.root [ 0 ] .plan [ `` Alias '' ] == `` comments '' assert qep.root [ 0 ] .plan [ `` Relation Name '' ] == `` stories '' `` `` '' Performs analyses on given queries , returning resultant QEPAnalysis . '' '' '' return self._qep [ `` Plan '' ] qep = parser ( `` select * from users where id = 1 or id = 2 '' ) self._conn : connection = conn or psycopg2.connect ( * args , * * kwargs ) postgresql = factories.postgresql ( `` postgresql_in_docker '' ) stmt : The query to execute . return self._node.__repr__ ( ) insert into stories ( name ) values ( 'story2 ' ) ; from psycopg2.extensions import connection from pytest_postgresql import factories `` Node Type '' : str , assert qep.plan [ `` Alias '' ] == `` comments '' assert qep.plan [ `` Node Type '' ] == `` Result '' Returns : def __repr__ ( self ) : assert qep.root [ 0 ] .plan [ `` Relation Name '' ] == `` users '' load= [ load_database ] , insert into users ( name ) values ( 'user2 ' ) ; def __getitem__ ( self , key : int ) - > `` QEPNode '' : `` Actual Startup Time '' : float , `` Plan Width '' : int , assert qep.plan [ `` Actual Rows '' ] == 1 raise ValueError ( f '' Expected 1 column , got { n } '' ) assert qep.root [ 0 ] .plan [ `` Relation Name '' ] == `` comments '' * args : Positional arguments to pass to cursor.execute ( ) . user=getenv ( `` POSTGRES_USER '' , `` postgres '' ) , class QEPNode : user_id integer references users ( id ) on delete cascade , def find ( self , pred : Callable [ [ node ] , bool ] ) - > list [ node ] :","['.gitattributes', 'qepparser.py', 'test_qepparser.py']",2022-09-23 11:57:31+00:00,2022-10-13 10:28:11+00:00,2022-10-11 17:32:29+03:00
12,672575a8e3f414ce9ffa1f47b1e18b13d13fb9eb,4.038352199131623e-05,0,"Turn an SQL statement , its results , and a QEP into an insightful message to the user . # 6 # 7 # 8 # 9",Basic semantic analysis,Merge pull request # 44 from Project-C-SQL/feat/improve-qeps,"assert len ( qep.root.rfindval ( `` Node Type '' , `` Bitmap Heap Scan '' ) ) == 1 return self.find ( pred , recursive=True ) `` `` '' Finds nodes with the given key and value . assert qep.root.findval ( `` Alias '' , `` users '' ) == [ qep.plan ] assert qep.root.findval ( `` Actual Rows '' , 4 ) == [ qep.plan ] self._ref = bool ( conn ) assert qep.root.findval ( `` Actual Rows '' , 2 ) == [ qep.plan ] : param key : the key to search for To install all dependencies and the application , type ` poetry install ` . After installation , if the Python scripts folder is in your PATH , you should be able to invoke ` main.main ( ) ` with ` pg4n ` . : param key : the index of the child node to get qep = parser ( `` select * from comments where id = 1 '' ) password=getenv ( `` PGPASSWORD '' ) , Having PostgreSQL running on port 5432 , do ` poetry run pytest ` ( or , if on port x , just do ` PGPORT=x poetry run pytest ` ) . `` `` '' Test that the QEP find method works as expected . '' '' '' : returns : the child node at the given index `` `` '' Test that the QEP rfind ( recursive find ) method works as expected . '' '' '' return map ( QEPNode , self._node.get ( `` Plans '' , [ ] ) ) list ( chain.from_iterable ( x.find ( pr , True ) for x in iter ( self ) ) ) | -- -- -- -- -- -- | -- -- -- -- -- -- -- - | -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - | return self._node.get ( `` Plans '' , [ ] ) `` `` '' Finds nodes matching the predicate . assert qep.root.findval ( `` Alias '' , `` comments '' ) == [ qep.plan ] | ` PGDBNAME ` | ` test_database ` | Database name . | return self.find ( lambda x : x.get ( key ) == val , recursive ) : param val : the value to search for if recursive : def rfindval ( self , key : str , val : object ) - > list [ node ] : stmt = f '' explain ( format json , analyze , verbose ) { stmt.strip ( ) .rstrip ( ' ; ' ) } ; '' | Variable | Default value | Description | assert len ( qep.root.rfindval ( `` Node Type '' , `` BitmapOr '' ) ) == 2 | ` PGPASSWORD ` | | Password , in case password authentication is used . | qep = parser ( `` select * from stories where id = 1 '' ) assert qep.root.findval ( `` Alias '' , `` stories '' ) == [ qep.plan ] return map ( QEPNode , self._node [ `` Plans '' ] ) : param pr : a function that takes a node and returns True if it matches qep = parser ( `` select * from stories where id = 1 or id = 2 '' ) `` `` '' Get the child node at the given index . '' '' '' def rfind ( self , pred : Callable [ [ node ] , bool ] ) - > list [ node ] : assert qep.root.findval ( `` Relation Name '' , `` stories '' ) == [ qep.plan ] qep = parser ( `` select * from users where id = 1 '' ) | ` PGPORT ` | ` 5432 ` | Port to an active PostgreSQL instance . | this+children To install all dependencies and the application , type ` poetry install ` . After installation , if the Python scripts folder is in your PATH , you should be able to invoke ` main.main ( ) ` with ` pg4n ` . : param node_ : the node to wrap '' '' '' return self.find ( pr ) + \ self._conn.commit ( ) qep = parser ( `` select * from users '' ) | ` PGUSER ` | ` postgres ` | The user that will be used to manage the test database . | recursive=False ) - > list [ node ] : return self._node [ `` Plans '' ] with self._conn.cursor ( ) as cur : `` `` '' Finds nodes with the given key and value , recursively . : param pred : a function that takes a node and returns True if it matches : returns : a list of matching nodes Having PostgreSQL running on port 5432 , do ` poetry run pytest ` . qep = parser ( `` select * from users where id = 1 or id = 2 '' ) return self.findval ( key , val , recursive=True ) `` `` '' Find nodes matching the predicate . '' '' '' qep = parser ( `` select * from comments where id = 1 or id = 2 '' ) # use constraint_exclusion to avoid unnecessary index scans assert len ( qep.root.rfindval ( `` Node Type '' , `` Bitmap Index Scan '' ) ) == 4 def test_qep_find ( parser : qepparser.QEPParser ) : qep = parser ( `` select * from comments '' ) self._ref = not not conn def find ( self , pred : Callable [ [ node ] , bool ] ) - > list [ node ] : For example , if PostgreSQL is on port 5433 , just do ` PGPORT=5433 poetry run pytest ` ( Bash syntax ) . assert qep.root.findval ( `` Node Type '' , `` Seq Scan '' ) == [ qep.plan ] assert qep.root.findval ( `` Actual Rows '' , 1 ) == [ qep.plan ] def test_gep_rfind ( parser : qepparser.QEPParser ) : To get a similar instance as with GitHub Actions workflow : < br > : param recursive : if True , search recursively , otherwise only search `` `` '' Create a new QEPNode . qep = parser ( `` select * from stories '' ) def findval ( self , key : str , val : object , recursive=False ) - > list [ node ] : return list ( filter ( pr , chain ( ( self._node , ) , self.plans ) ) ) `` `` '' Get the child node at the given index . def find ( self , pr : Callable [ [ node ] , bool ] , dbname=getenv ( `` PGDBNAME '' , `` test_database '' ) ) return list ( filter ( pred , self._node [ `` Plans '' ] ) ) You may need to provide environment variables that match your config : from itertools import chain stmt.strip ( ) .rstrip ( ' ; ' ) + `` ; '' password=getenv ( `` PGPASSWORD '' , `` postgres '' ) ) `` `` '' cur.execute ( `` set constraint_exclusion = on ; '' ) stmt = `` explain ( format json , analyze , verbose ) '' + \ | ` PGHOST ` | ` 127.0.0.1 ` | Hostname of the PostgreSQL server . | assert qep.root.findval ( `` Relation Name '' , `` users '' ) == [ qep.plan ] assert qep.root.findval ( `` Node Type '' , `` Index Scan '' ) == [ qep.plan ] assert qep.root.findval ( `` Relation Name '' , `` comments '' ) == [ qep.plan ] To get a similar PostgreSQL instance as with GitHub Actions workflow : < br > `` `` '' Finds nodes matching the predicate , recursively .","['README.md', 'src/pg4n/qepparser.py', 'src/pg4n/test/test_qepparser.py']",2022-09-23 11:57:31+00:00,2022-10-13 10:28:11+00:00,2022-11-05 13:28:47+02:00
12,bbd831ee1f05324f62486eca5ace30ed845111a7,0.0001493374584242,0,"Turn an SQL statement , its results , and a QEP into an insightful message to the user . # 6 # 7 # 8 # 9",Basic semantic analysis,Merge pull request # 77 from Project-C-SQL/feat/errfmt,"warning_msg = `` Warning : Possible use of '= ' instead of % for wildcard pattern [ pg4n : :EqWildcard ] '' formatter = ErrorFormatter ( warning , warning_name ) msg_header = f '' Warning : Comparison between different domains ( { domain1 } , { domain2 } ) [ pg4n : :CmpDomains ] \n '' warning_name = `` SumDistinct '' self.warning_msg = self.warning_msg + msg_header + underlined_query formatter = ErrorFormatter ( warning , warning_name ) from . qepparser import QEPAnalysis warning_name = `` EqWildcard '' warning_name = `` SubquerySelect '' ) self.warning_msg = formatter.format ( ) warning_name = `` StrangeHaving '' VT100_RESET = `` \x1b [ 0m '' warning = `` DISTINCT in SUM or AVG '' warning_name = `` CmpDomains '' warning_name = `` SurplusSemicolons '' warning_name = `` InnerOrderBy '' warning = `` ORDER BY in a subquery '' warning_msg = `` Warning : ORDER BY in a subquery [ pg4n : :InnerOrderBy ] '' warning_name = `` ImpliedExpression '' warning_msg = `` Warning : DISTINCT in SUM or AVG [ pg4n : :SumDistinct ] '' self.warning_name : str = warning_name warning_header = `` Warning : No column in subquery SELECT references its tables [ pg4n : :SubquerySelect ] \n '' warning_msg = formatter.format ( ) self.underlined_query : Optional [ str ] = underlined_query warning = `` Too many semicolons '' assert ( warning = `` No column in subquery SELECT references its tables '' formatter = ErrorFormatter ( warning , warning_name , underlined_query ) warning_msg.find ( warning ) ! = -1 self.warning_msg : str = warning_msg warning_msg += formatter.format ( ) warning = `` HAVING without GROUP BY '' from typing import Optional underlined_query : Optional [ str ] = None , assert warning_msg.find ( warning ) ! = -1 and warning_msg.find ( warning_name ) ! = -1 def __init__ ( warning = `` Too many parentheses '' warning_name = `` SurplusParentheses '' from .qepparser import QEPAnalysis FROM customers ) : class ErrorFormatter : and warning_msg.find ( warning_name ) ! = -1 warning = f '' Comparison between different domains ( { domain1 } , { domain2 } ) '' Returns a formatted error message . return base_msg warning = `` Found impossible comparison due to column/table constraints '' def test_format ( ) : self , formatter = ErrorFormatter ( warning , warning_name , underlined_query ) from .errfmt import ErrorFormatter underlined_query = f '' '' '' SELECT * from .. errfmt import ErrorFormatter warning_name : str , base_msg = f '' Warning : { self.warning_msg } [ pg4n : : { self.warning_name } ] '' warning_msg = `` Warning : HAVING without GROUP BY [ pg4n : :StrangeHaving ] '' if self.underlined_query : warning_msg = `` Warning : Found impossible comparison due to column/table constraints [ pg4n : :ImpliedExpression ] '' warning = `` Possible use of '= ' instead of LIKE for wildcard pattern '' def format ( self ) - > str : `` `` '' and warning_msg.find ( underlined_query ) ! = -1 VT100_UNDERLINE = `` \x1b [ 4m '' warning_msg : str , warning_msg += warning_header + underlined_query { VT100_UNDERLINE } WHERE type ' C ' { VT100_RESET } = 1 OR 100 = 100 ; '' '' '' return base_msg + f '' \n { self.underlined_query } '' warning_msg = formatter.format ( )","['src/pg4n/cmp_domain_checker.py', 'src/pg4n/eq_wildcard_checker.py', 'src/pg4n/errfmt.py', 'src/pg4n/implied_expression_checker.py', 'src/pg4n/strange_having_checker.py', 'src/pg4n/subquery_orderby_checker.py', 'src/pg4n/subquery_select_checker.py', 'src/pg4n/sum_distinct_checker.py', 'src/pg4n/test/test_errfmt.py']",2022-09-23 11:57:31+00:00,2022-10-13 10:28:11+00:00,2022-11-21 12:21:55+02:00
12,3d6dec83450eb47b7c1c89380c7d32be851a2780,3.319583265692927e-05,0,"Turn an SQL statement , its results , and a QEP into an insightful message to the user . # 6 # 7 # 8 # 9",Basic semantic analysis,Merge pull request # 97 from Project-C-SQL/fix/qepparser-crash,"if self.qep_analysis is None : return QEPAnalysis ( res [ 0 ] [ 0 ] [ 0 ] ) with self._conn.cursor ( ) as cur : raise ValueError ( f '' Expected 1 row , got { n } '' ) if ( n : = len ( res ) ) ! = 1 : return QEPAnalysis ( res [ 0 ] [ 0 ] [ 0 ] ) if ( n : = len ( res [ 0 ] ) ) ! = 1 : try : if ( t : = type ( res [ 0 ] [ 0 ] [ 0 ] ) ) ! = dict : self._conn.commit ( ) cur.execute ( `` set constraint_exclusion = on ; '' ) raise ValueError ( f '' Expected 1 item in column , got { n } '' ) if ( t : = type ( res [ 0 ] [ 0 ] [ 0 ] ) ) ! = dict : if qep_analysis_with_constraint_exclusion is None : cur.execute ( stmt , * args , * * kwargs ) if ( n : = len ( res ) ) ! = 1 : with self._conn.cursor ( ) as cur : if ( n : = len ( res [ 0 ] [ 0 ] ) ) ! = 1 : cur.execute ( `` set constraint_exclusion = off ; '' ) cur.execute ( `` set constraint_exclusion = on ; '' ) if ( n : = len ( res [ 0 ] [ 0 ] ) ) ! = 1 : if qep_analysis_without_constraint_exclusion is None : raise ValueError ( f '' Expected 1 row , got { n } '' ) raise ValueError ( f '' Expected dict in column , got { t } '' ) self._conn.rollback ( ) self._conn.commit ( ) self._conn.rollback ( ) cur.execute ( `` set constraint_exclusion = off ; '' ) cur.execute ( stmt , * args , * * kwargs ) except Exception as e : try : res = cur.fetchall ( ) raise ValueError ( f '' Expected 1 column , got { n } '' ) return None res = cur.fetchall ( ) raise ValueError ( f '' Expected 1 item in column , got { n } '' ) raise ValueError ( f '' Expected 1 column , got { n } '' ) stmt = `` explain ( format json , analyze , verbose ) '' + \ stmt = `` explain ( format json , analyze , verbose ) `` + \ if ( n : = len ( res [ 0 ] ) ) ! = 1 : except psycopg.Error as e : raise ValueError ( f '' Expected dict in column , got { t } '' )","['src/pg4n/implied_expression_checker.py', 'src/pg4n/qepparser.py', 'src/pg4n/subquery_order_by_checker.py']",2022-09-23 11:57:31+00:00,2022-10-13 10:28:11+00:00,2022-12-16 13:05:50+02:00
19,6c5e663747462817aa670b59addb191b618c5eb9,3.893686516676098e-05,0,Design required classes and interfaces according to SOLID principles and potentially GoF design patterns . Document them in wiki .,Document architecture and interfaces for QEP parser,Merge pull request # 29 from Project-C-SQL/feat/qep-parser,"`` `` '' Represents the result of EXPLAIN ANALYZE . '' '' '' `` Scan Direction '' : str , assert qep.plan [ `` Node Type '' ] == `` Seq Scan '' return QEPNode ( self._node [ `` Plans '' ] [ key ] ) `` Triggers '' : list [ str ] , for copy-and-pasting `` Plans '' : List [ `` node '' ] , create table comments ( node = TypedDict ( `` Plan '' , { assert qep.plan [ `` Actual Rows '' ] == 4 `` Plan Rows '' : int , assert qep.plan [ `` Relation Name '' ] == `` comments '' return self ( stmt , * args , * * kwargs ) `` Parent Relationship '' : str , story_id integer references stories ( id ) on delete cascade , import qepparser conn : connection = psycopg2.connect ( * * kwargs ) * * kwargs : Keyword arguments to pass to cursor.execute ( ) . postgresql_in_docker = factories.postgresql_noproc ( self._ref = not not conn qep = parser ( `` select * from users where id = 1 and id = 2 '' ) def plan ( self ) - > node : assert qep.plan [ `` Relation Name '' ] == `` stories '' raise ValueError ( f '' Expected dict in column , got { t } '' ) # TODO : break into variants discriminated by Node Type return self._node return qepparser.QEPParser ( conn=postgresql ) * text=auto def load_database ( * * kwargs ) : import psycopg2 `` `` '' A dict of the query execution plan 's properties . '' '' '' def __call__ ( self , stmt : str , * args , * * kwargs ) - > QEPAnalysis : return list ( filter ( pred , self._node [ `` Plans '' ] ) ) qep = parser ( `` select * from stories where id = 1 '' ) def __init__ ( self , qep_ : qep ) : return self._node.__str__ ( ) def __init__ ( self , node_ : node ) : qep = parser ( `` select * from stories where id = 1 and id = 2 '' ) return map ( QEPNode , self._node [ `` Plans '' ] ) password=getenv ( `` POSTGRES_PASSWORD '' , `` postgres '' ) ) qep = parser ( `` select * from stories where id = 1 or id = 2 '' ) if ( n : = len ( res [ 0 ] ) ) ! = 1 : self._node = node_ insert into comments ( story_id , user_id , comment ) values ( 2 , 1 , 'comment3 ' ) ; insert into comments ( story_id , user_id , comment ) values ( 1 , 2 , 'comment2 ' ) ; qep = parser ( `` select * from users where id = 1 '' ) def __len__ ( self ) - > int : return self._node [ `` Plans '' ] `` Actual Total Time '' : float , `` `` '' A dict of the root node 's properties . '' '' '' `` `` '' The root node of the query execution plan . '' '' '' qep = parser ( `` select * from users '' ) assert qep.plan [ `` Actual Rows '' ] == 2 `` Filter '' : str , return self._qep.__repr__ ( ) `` `` '' Iterate over child nodes . '' '' '' if ( n : = len ( res [ 0 ] [ 0 ] ) ) ! = 1 : import pytest with self._conn.cursor ( ) as cur : insert into stories ( name ) values ( 'story1 ' ) ; # are available for each node type assert qep.plan [ `` Node Type '' ] == `` Index Scan '' if ( t : = type ( res [ 0 ] [ 0 ] [ 0 ] ) ) ! = dict : if not self._ref : `` Alias '' : str , qep = parser ( `` select * from comments where id = 1 and id = 2 '' ) def plans ( self ) - > list [ node ] : `` Planning Time '' : float , insert into comments ( story_id , user_id , comment ) values ( 1 , 1 , 'comment1 ' ) ; return self._qep def __del__ ( self ) : `` Execution Time '' : float , create table stories ( id serial primary key , name varchar ) ; self._qep = qep_ return QEPNode ( self._qep [ `` Plan '' ] ) assert qep.plan [ `` Relation Name '' ] == `` users '' class QEPAnalysis : qep = TypedDict ( `` QEP '' , { qep = parser ( `` select * from comments '' ) `` `` '' Test that the QEP structure is as expected . '' '' '' self._conn.close ( ) raise ValueError ( f '' Expected 1 row , got { n } '' ) assert qep.root [ 0 ] .plan [ `` Actual Rows '' ] == 0 assert qep.plan [ `` Node Type '' ] == `` Bitmap Heap Scan '' qep = parser ( `` select * from stories '' ) `` `` '' Get the number of child nodes . '' '' '' insert into comments ( story_id , user_id , comment ) values ( 2 , 2 , 'comment4 ' ) ; def parser ( postgresql : connection ) : Executes a query and returns the query execution plan as a dictionary . `` `` '' } ) cur.execute ( `` '' '' drop table if exists users ; return QEPAnalysis ( res [ 0 ] [ 0 ] [ 0 ] ) create table users ( id serial primary key , name varchar ) ; demonstrates relational data assert qep.root [ 0 ] .plan [ `` Alias '' ] == `` users '' Parameters : id serial primary key , def parse ( self , stmt : str , * args , * * kwargs ) - > QEPAnalysis : `` Plan '' : node , from typing import Callable , Iterable , List , TypedDict qep = parser ( `` select * from comments where id = 1 '' ) `` Total Cost '' : float , res = cur.fetchall ( ) `` Index Name '' : str , assert qep.root [ 0 ] .plan [ `` Node Type '' ] == `` Index Scan '' `` `` '' Find nodes matching the predicate . '' '' '' `` Total Runtime '' : float , `` `` '' Get the child node at the given index . '' '' '' def root ( self ) - > QEPNode : return len ( self._node [ `` Plans '' ] ) assert qep.plan [ `` Alias '' ] == `` users '' class QEPParser : def test_qep_structure ( parser : qepparser.QEPParser ) : from os import getenv conn.commit ( ) assert qep.plan [ `` Alias '' ] == `` stories '' cur.execute ( stmt , * args , * * kwargs ) def qep ( self ) - > qep : drop table if exists stories ; comment varchar ) ; insert into users ( name ) values ( 'user1 ' ) ; if ( n : = len ( res ) ) ! = 1 : `` Startup Cost '' : float , '' 'Alias for __call__ '' ' `` Relation Name '' : str , raise ValueError ( f '' Expected 1 item in column , got { n } '' ) return self._qep.__str__ ( ) `` Index Cond '' : str , assert qep.root [ 0 ] .plan [ `` Alias '' ] == `` stories '' def __init__ ( self , * args , conn=None , * * kwargs ) : `` Actual Loops '' : int , self._conn.rollback ( ) # right now , the interface is n't safe to use because it 's not clear what fields def __iter__ ( self ) - > Iterable [ `` QEPNode '' ] : def __str__ ( self ) : stmt = f '' explain ( format json , analyze , verbose ) { stmt.strip ( ) .rstrip ( ' ; ' ) } ; '' A dictionary representing the query execution plan . drop table if exists comments ; `` `` '' A node in a query execution plan . '' '' '' `` `` '' A list of the node 's children . '' '' '' `` `` '' A dict of the node 's properties . '' '' '' with conn.cursor ( ) as cur : `` `` '' ) `` Actual Rows '' : int , populate with sample data assert qep.root [ 0 ] .plan [ `` Alias '' ] == `` comments '' assert qep.root [ 0 ] .plan [ `` Relation Name '' ] == `` stories '' `` `` '' Performs analyses on given queries , returning resultant QEPAnalysis . '' '' '' return self._qep [ `` Plan '' ] qep = parser ( `` select * from users where id = 1 or id = 2 '' ) self._conn : connection = conn or psycopg2.connect ( * args , * * kwargs ) postgresql = factories.postgresql ( `` postgresql_in_docker '' ) stmt : The query to execute . return self._node.__repr__ ( ) insert into stories ( name ) values ( 'story2 ' ) ; from psycopg2.extensions import connection from pytest_postgresql import factories `` Node Type '' : str , assert qep.plan [ `` Alias '' ] == `` comments '' assert qep.plan [ `` Node Type '' ] == `` Result '' Returns : def __repr__ ( self ) : assert qep.root [ 0 ] .plan [ `` Relation Name '' ] == `` users '' load= [ load_database ] , insert into users ( name ) values ( 'user2 ' ) ; def __getitem__ ( self , key : int ) - > `` QEPNode '' : `` Actual Startup Time '' : float , `` Plan Width '' : int , assert qep.plan [ `` Actual Rows '' ] == 1 raise ValueError ( f '' Expected 1 column , got { n } '' ) assert qep.root [ 0 ] .plan [ `` Relation Name '' ] == `` comments '' * args : Positional arguments to pass to cursor.execute ( ) . user=getenv ( `` POSTGRES_USER '' , `` postgres '' ) , class QEPNode : user_id integer references users ( id ) on delete cascade , def find ( self , pred : Callable [ [ node ] , bool ] ) - > list [ node ] :","['.gitattributes', 'qepparser.py', 'test_qepparser.py']",2022-09-29 09:56:52+00:00,2022-11-10 10:38:31+00:00,2022-10-11 17:32:29+03:00
22,672575a8e3f414ce9ffa1f47b1e18b13d13fb9eb,3.114266655757092e-05,0,See # 10 Look into psql output given ` explain analyze ` with potential machine-readable formatting options .,Analyze QEP format,Merge pull request # 44 from Project-C-SQL/feat/improve-qeps,"assert len ( qep.root.rfindval ( `` Node Type '' , `` Bitmap Heap Scan '' ) ) == 1 return self.find ( pred , recursive=True ) `` `` '' Finds nodes with the given key and value . assert qep.root.findval ( `` Alias '' , `` users '' ) == [ qep.plan ] assert qep.root.findval ( `` Actual Rows '' , 4 ) == [ qep.plan ] self._ref = bool ( conn ) assert qep.root.findval ( `` Actual Rows '' , 2 ) == [ qep.plan ] : param key : the key to search for To install all dependencies and the application , type ` poetry install ` . After installation , if the Python scripts folder is in your PATH , you should be able to invoke ` main.main ( ) ` with ` pg4n ` . : param key : the index of the child node to get qep = parser ( `` select * from comments where id = 1 '' ) password=getenv ( `` PGPASSWORD '' ) , Having PostgreSQL running on port 5432 , do ` poetry run pytest ` ( or , if on port x , just do ` PGPORT=x poetry run pytest ` ) . `` `` '' Test that the QEP find method works as expected . '' '' '' : returns : the child node at the given index `` `` '' Test that the QEP rfind ( recursive find ) method works as expected . '' '' '' return map ( QEPNode , self._node.get ( `` Plans '' , [ ] ) ) list ( chain.from_iterable ( x.find ( pr , True ) for x in iter ( self ) ) ) | -- -- -- -- -- -- | -- -- -- -- -- -- -- - | -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - | return self._node.get ( `` Plans '' , [ ] ) `` `` '' Finds nodes matching the predicate . assert qep.root.findval ( `` Alias '' , `` comments '' ) == [ qep.plan ] | ` PGDBNAME ` | ` test_database ` | Database name . | return self.find ( lambda x : x.get ( key ) == val , recursive ) : param val : the value to search for if recursive : def rfindval ( self , key : str , val : object ) - > list [ node ] : stmt = f '' explain ( format json , analyze , verbose ) { stmt.strip ( ) .rstrip ( ' ; ' ) } ; '' | Variable | Default value | Description | assert len ( qep.root.rfindval ( `` Node Type '' , `` BitmapOr '' ) ) == 2 | ` PGPASSWORD ` | | Password , in case password authentication is used . | qep = parser ( `` select * from stories where id = 1 '' ) assert qep.root.findval ( `` Alias '' , `` stories '' ) == [ qep.plan ] return map ( QEPNode , self._node [ `` Plans '' ] ) : param pr : a function that takes a node and returns True if it matches qep = parser ( `` select * from stories where id = 1 or id = 2 '' ) `` `` '' Get the child node at the given index . '' '' '' def rfind ( self , pred : Callable [ [ node ] , bool ] ) - > list [ node ] : assert qep.root.findval ( `` Relation Name '' , `` stories '' ) == [ qep.plan ] qep = parser ( `` select * from users where id = 1 '' ) | ` PGPORT ` | ` 5432 ` | Port to an active PostgreSQL instance . | this+children To install all dependencies and the application , type ` poetry install ` . After installation , if the Python scripts folder is in your PATH , you should be able to invoke ` main.main ( ) ` with ` pg4n ` . : param node_ : the node to wrap '' '' '' return self.find ( pr ) + \ self._conn.commit ( ) qep = parser ( `` select * from users '' ) | ` PGUSER ` | ` postgres ` | The user that will be used to manage the test database . | recursive=False ) - > list [ node ] : return self._node [ `` Plans '' ] with self._conn.cursor ( ) as cur : `` `` '' Finds nodes with the given key and value , recursively . : param pred : a function that takes a node and returns True if it matches : returns : a list of matching nodes Having PostgreSQL running on port 5432 , do ` poetry run pytest ` . qep = parser ( `` select * from users where id = 1 or id = 2 '' ) return self.findval ( key , val , recursive=True ) `` `` '' Find nodes matching the predicate . '' '' '' qep = parser ( `` select * from comments where id = 1 or id = 2 '' ) # use constraint_exclusion to avoid unnecessary index scans assert len ( qep.root.rfindval ( `` Node Type '' , `` Bitmap Index Scan '' ) ) == 4 def test_qep_find ( parser : qepparser.QEPParser ) : qep = parser ( `` select * from comments '' ) self._ref = not not conn def find ( self , pred : Callable [ [ node ] , bool ] ) - > list [ node ] : For example , if PostgreSQL is on port 5433 , just do ` PGPORT=5433 poetry run pytest ` ( Bash syntax ) . assert qep.root.findval ( `` Node Type '' , `` Seq Scan '' ) == [ qep.plan ] assert qep.root.findval ( `` Actual Rows '' , 1 ) == [ qep.plan ] def test_gep_rfind ( parser : qepparser.QEPParser ) : To get a similar instance as with GitHub Actions workflow : < br > : param recursive : if True , search recursively , otherwise only search `` `` '' Create a new QEPNode . qep = parser ( `` select * from stories '' ) def findval ( self , key : str , val : object , recursive=False ) - > list [ node ] : return list ( filter ( pr , chain ( ( self._node , ) , self.plans ) ) ) `` `` '' Get the child node at the given index . def find ( self , pr : Callable [ [ node ] , bool ] , dbname=getenv ( `` PGDBNAME '' , `` test_database '' ) ) return list ( filter ( pred , self._node [ `` Plans '' ] ) ) You may need to provide environment variables that match your config : from itertools import chain stmt.strip ( ) .rstrip ( ' ; ' ) + `` ; '' password=getenv ( `` PGPASSWORD '' , `` postgres '' ) ) `` `` '' cur.execute ( `` set constraint_exclusion = on ; '' ) stmt = `` explain ( format json , analyze , verbose ) '' + \ | ` PGHOST ` | ` 127.0.0.1 ` | Hostname of the PostgreSQL server . | assert qep.root.findval ( `` Relation Name '' , `` users '' ) == [ qep.plan ] assert qep.root.findval ( `` Node Type '' , `` Index Scan '' ) == [ qep.plan ] assert qep.root.findval ( `` Relation Name '' , `` comments '' ) == [ qep.plan ] To get a similar PostgreSQL instance as with GitHub Actions workflow : < br > `` `` '' Finds nodes matching the predicate , recursively .","['README.md', 'src/pg4n/qepparser.py', 'src/pg4n/test/test_qepparser.py']",2022-09-29 10:32:05+00:00,2022-10-11 14:32:31+00:00,2022-11-05 13:28:47+02:00
22,bbd831ee1f05324f62486eca5ace30ed845111a7,0.966431736946106,0,See # 10 Look into psql output given ` explain analyze ` with potential machine-readable formatting options .,Analyze QEP format,Merge pull request # 77 from Project-C-SQL/feat/errfmt,"warning_msg = `` Warning : Possible use of '= ' instead of % for wildcard pattern [ pg4n : :EqWildcard ] '' formatter = ErrorFormatter ( warning , warning_name ) msg_header = f '' Warning : Comparison between different domains ( { domain1 } , { domain2 } ) [ pg4n : :CmpDomains ] \n '' warning_name = `` SumDistinct '' self.warning_msg = self.warning_msg + msg_header + underlined_query formatter = ErrorFormatter ( warning , warning_name ) from . qepparser import QEPAnalysis warning_name = `` EqWildcard '' warning_name = `` SubquerySelect '' ) self.warning_msg = formatter.format ( ) warning_name = `` StrangeHaving '' VT100_RESET = `` \x1b [ 0m '' warning = `` DISTINCT in SUM or AVG '' warning_name = `` CmpDomains '' warning_name = `` SurplusSemicolons '' warning_name = `` InnerOrderBy '' warning = `` ORDER BY in a subquery '' warning_msg = `` Warning : ORDER BY in a subquery [ pg4n : :InnerOrderBy ] '' warning_name = `` ImpliedExpression '' warning_msg = `` Warning : DISTINCT in SUM or AVG [ pg4n : :SumDistinct ] '' self.warning_name : str = warning_name warning_header = `` Warning : No column in subquery SELECT references its tables [ pg4n : :SubquerySelect ] \n '' warning_msg = formatter.format ( ) self.underlined_query : Optional [ str ] = underlined_query warning = `` Too many semicolons '' assert ( warning = `` No column in subquery SELECT references its tables '' formatter = ErrorFormatter ( warning , warning_name , underlined_query ) warning_msg.find ( warning ) ! = -1 self.warning_msg : str = warning_msg warning_msg += formatter.format ( ) warning = `` HAVING without GROUP BY '' from typing import Optional underlined_query : Optional [ str ] = None , assert warning_msg.find ( warning ) ! = -1 and warning_msg.find ( warning_name ) ! = -1 def __init__ ( warning = `` Too many parentheses '' warning_name = `` SurplusParentheses '' from .qepparser import QEPAnalysis FROM customers ) : class ErrorFormatter : and warning_msg.find ( warning_name ) ! = -1 warning = f '' Comparison between different domains ( { domain1 } , { domain2 } ) '' Returns a formatted error message . return base_msg warning = `` Found impossible comparison due to column/table constraints '' def test_format ( ) : self , formatter = ErrorFormatter ( warning , warning_name , underlined_query ) from .errfmt import ErrorFormatter underlined_query = f '' '' '' SELECT * from .. errfmt import ErrorFormatter warning_name : str , base_msg = f '' Warning : { self.warning_msg } [ pg4n : : { self.warning_name } ] '' warning_msg = `` Warning : HAVING without GROUP BY [ pg4n : :StrangeHaving ] '' if self.underlined_query : warning_msg = `` Warning : Found impossible comparison due to column/table constraints [ pg4n : :ImpliedExpression ] '' warning = `` Possible use of '= ' instead of LIKE for wildcard pattern '' def format ( self ) - > str : `` `` '' and warning_msg.find ( underlined_query ) ! = -1 VT100_UNDERLINE = `` \x1b [ 4m '' warning_msg : str , warning_msg += warning_header + underlined_query { VT100_UNDERLINE } WHERE type ' C ' { VT100_RESET } = 1 OR 100 = 100 ; '' '' '' return base_msg + f '' \n { self.underlined_query } '' warning_msg = formatter.format ( )","['src/pg4n/cmp_domain_checker.py', 'src/pg4n/eq_wildcard_checker.py', 'src/pg4n/errfmt.py', 'src/pg4n/implied_expression_checker.py', 'src/pg4n/strange_having_checker.py', 'src/pg4n/subquery_orderby_checker.py', 'src/pg4n/subquery_select_checker.py', 'src/pg4n/sum_distinct_checker.py', 'src/pg4n/test/test_errfmt.py']",2022-09-29 10:32:05+00:00,2022-10-11 14:32:31+00:00,2022-11-21 12:21:55+02:00
22,3d6dec83450eb47b7c1c89380c7d32be851a2780,6.111121183494106e-05,0,See # 10 Look into psql output given ` explain analyze ` with potential machine-readable formatting options .,Analyze QEP format,Merge pull request # 97 from Project-C-SQL/fix/qepparser-crash,"if self.qep_analysis is None : return QEPAnalysis ( res [ 0 ] [ 0 ] [ 0 ] ) with self._conn.cursor ( ) as cur : raise ValueError ( f '' Expected 1 row , got { n } '' ) if ( n : = len ( res ) ) ! = 1 : return QEPAnalysis ( res [ 0 ] [ 0 ] [ 0 ] ) if ( n : = len ( res [ 0 ] ) ) ! = 1 : try : if ( t : = type ( res [ 0 ] [ 0 ] [ 0 ] ) ) ! = dict : self._conn.commit ( ) cur.execute ( `` set constraint_exclusion = on ; '' ) raise ValueError ( f '' Expected 1 item in column , got { n } '' ) if ( t : = type ( res [ 0 ] [ 0 ] [ 0 ] ) ) ! = dict : if qep_analysis_with_constraint_exclusion is None : cur.execute ( stmt , * args , * * kwargs ) if ( n : = len ( res ) ) ! = 1 : with self._conn.cursor ( ) as cur : if ( n : = len ( res [ 0 ] [ 0 ] ) ) ! = 1 : cur.execute ( `` set constraint_exclusion = off ; '' ) cur.execute ( `` set constraint_exclusion = on ; '' ) if ( n : = len ( res [ 0 ] [ 0 ] ) ) ! = 1 : if qep_analysis_without_constraint_exclusion is None : raise ValueError ( f '' Expected 1 row , got { n } '' ) raise ValueError ( f '' Expected dict in column , got { t } '' ) self._conn.rollback ( ) self._conn.commit ( ) self._conn.rollback ( ) cur.execute ( `` set constraint_exclusion = off ; '' ) cur.execute ( stmt , * args , * * kwargs ) except Exception as e : try : res = cur.fetchall ( ) raise ValueError ( f '' Expected 1 column , got { n } '' ) return None res = cur.fetchall ( ) raise ValueError ( f '' Expected 1 item in column , got { n } '' ) raise ValueError ( f '' Expected 1 column , got { n } '' ) stmt = `` explain ( format json , analyze , verbose ) '' + \ stmt = `` explain ( format json , analyze , verbose ) `` + \ if ( n : = len ( res [ 0 ] ) ) ! = 1 : except psycopg.Error as e : raise ValueError ( f '' Expected dict in column , got { t } '' )","['src/pg4n/implied_expression_checker.py', 'src/pg4n/qepparser.py', 'src/pg4n/subquery_order_by_checker.py']",2022-09-29 10:32:05+00:00,2022-10-11 14:32:31+00:00,2022-12-16 13:05:50+02:00
33,6c5e663747462817aa670b59addb191b618c5eb9,7.837291923351586e-05,0,Allow a visitor ( ? ) pattern for passing custom functions to examine tree structure for semantic analysis,Extend QEPAnalysis interface for easier analysis,Merge pull request # 29 from Project-C-SQL/feat/qep-parser,"`` `` '' Represents the result of EXPLAIN ANALYZE . '' '' '' `` Scan Direction '' : str , assert qep.plan [ `` Node Type '' ] == `` Seq Scan '' return QEPNode ( self._node [ `` Plans '' ] [ key ] ) `` Triggers '' : list [ str ] , for copy-and-pasting `` Plans '' : List [ `` node '' ] , create table comments ( node = TypedDict ( `` Plan '' , { assert qep.plan [ `` Actual Rows '' ] == 4 `` Plan Rows '' : int , assert qep.plan [ `` Relation Name '' ] == `` comments '' return self ( stmt , * args , * * kwargs ) `` Parent Relationship '' : str , story_id integer references stories ( id ) on delete cascade , import qepparser conn : connection = psycopg2.connect ( * * kwargs ) * * kwargs : Keyword arguments to pass to cursor.execute ( ) . postgresql_in_docker = factories.postgresql_noproc ( self._ref = not not conn qep = parser ( `` select * from users where id = 1 and id = 2 '' ) def plan ( self ) - > node : assert qep.plan [ `` Relation Name '' ] == `` stories '' raise ValueError ( f '' Expected dict in column , got { t } '' ) # TODO : break into variants discriminated by Node Type return self._node return qepparser.QEPParser ( conn=postgresql ) * text=auto def load_database ( * * kwargs ) : import psycopg2 `` `` '' A dict of the query execution plan 's properties . '' '' '' def __call__ ( self , stmt : str , * args , * * kwargs ) - > QEPAnalysis : return list ( filter ( pred , self._node [ `` Plans '' ] ) ) qep = parser ( `` select * from stories where id = 1 '' ) def __init__ ( self , qep_ : qep ) : return self._node.__str__ ( ) def __init__ ( self , node_ : node ) : qep = parser ( `` select * from stories where id = 1 and id = 2 '' ) return map ( QEPNode , self._node [ `` Plans '' ] ) password=getenv ( `` POSTGRES_PASSWORD '' , `` postgres '' ) ) qep = parser ( `` select * from stories where id = 1 or id = 2 '' ) if ( n : = len ( res [ 0 ] ) ) ! = 1 : self._node = node_ insert into comments ( story_id , user_id , comment ) values ( 2 , 1 , 'comment3 ' ) ; insert into comments ( story_id , user_id , comment ) values ( 1 , 2 , 'comment2 ' ) ; qep = parser ( `` select * from users where id = 1 '' ) def __len__ ( self ) - > int : return self._node [ `` Plans '' ] `` Actual Total Time '' : float , `` `` '' A dict of the root node 's properties . '' '' '' `` `` '' The root node of the query execution plan . '' '' '' qep = parser ( `` select * from users '' ) assert qep.plan [ `` Actual Rows '' ] == 2 `` Filter '' : str , return self._qep.__repr__ ( ) `` `` '' Iterate over child nodes . '' '' '' if ( n : = len ( res [ 0 ] [ 0 ] ) ) ! = 1 : import pytest with self._conn.cursor ( ) as cur : insert into stories ( name ) values ( 'story1 ' ) ; # are available for each node type assert qep.plan [ `` Node Type '' ] == `` Index Scan '' if ( t : = type ( res [ 0 ] [ 0 ] [ 0 ] ) ) ! = dict : if not self._ref : `` Alias '' : str , qep = parser ( `` select * from comments where id = 1 and id = 2 '' ) def plans ( self ) - > list [ node ] : `` Planning Time '' : float , insert into comments ( story_id , user_id , comment ) values ( 1 , 1 , 'comment1 ' ) ; return self._qep def __del__ ( self ) : `` Execution Time '' : float , create table stories ( id serial primary key , name varchar ) ; self._qep = qep_ return QEPNode ( self._qep [ `` Plan '' ] ) assert qep.plan [ `` Relation Name '' ] == `` users '' class QEPAnalysis : qep = TypedDict ( `` QEP '' , { qep = parser ( `` select * from comments '' ) `` `` '' Test that the QEP structure is as expected . '' '' '' self._conn.close ( ) raise ValueError ( f '' Expected 1 row , got { n } '' ) assert qep.root [ 0 ] .plan [ `` Actual Rows '' ] == 0 assert qep.plan [ `` Node Type '' ] == `` Bitmap Heap Scan '' qep = parser ( `` select * from stories '' ) `` `` '' Get the number of child nodes . '' '' '' insert into comments ( story_id , user_id , comment ) values ( 2 , 2 , 'comment4 ' ) ; def parser ( postgresql : connection ) : Executes a query and returns the query execution plan as a dictionary . `` `` '' } ) cur.execute ( `` '' '' drop table if exists users ; return QEPAnalysis ( res [ 0 ] [ 0 ] [ 0 ] ) create table users ( id serial primary key , name varchar ) ; demonstrates relational data assert qep.root [ 0 ] .plan [ `` Alias '' ] == `` users '' Parameters : id serial primary key , def parse ( self , stmt : str , * args , * * kwargs ) - > QEPAnalysis : `` Plan '' : node , from typing import Callable , Iterable , List , TypedDict qep = parser ( `` select * from comments where id = 1 '' ) `` Total Cost '' : float , res = cur.fetchall ( ) `` Index Name '' : str , assert qep.root [ 0 ] .plan [ `` Node Type '' ] == `` Index Scan '' `` `` '' Find nodes matching the predicate . '' '' '' `` Total Runtime '' : float , `` `` '' Get the child node at the given index . '' '' '' def root ( self ) - > QEPNode : return len ( self._node [ `` Plans '' ] ) assert qep.plan [ `` Alias '' ] == `` users '' class QEPParser : def test_qep_structure ( parser : qepparser.QEPParser ) : from os import getenv conn.commit ( ) assert qep.plan [ `` Alias '' ] == `` stories '' cur.execute ( stmt , * args , * * kwargs ) def qep ( self ) - > qep : drop table if exists stories ; comment varchar ) ; insert into users ( name ) values ( 'user1 ' ) ; if ( n : = len ( res ) ) ! = 1 : `` Startup Cost '' : float , '' 'Alias for __call__ '' ' `` Relation Name '' : str , raise ValueError ( f '' Expected 1 item in column , got { n } '' ) return self._qep.__str__ ( ) `` Index Cond '' : str , assert qep.root [ 0 ] .plan [ `` Alias '' ] == `` stories '' def __init__ ( self , * args , conn=None , * * kwargs ) : `` Actual Loops '' : int , self._conn.rollback ( ) # right now , the interface is n't safe to use because it 's not clear what fields def __iter__ ( self ) - > Iterable [ `` QEPNode '' ] : def __str__ ( self ) : stmt = f '' explain ( format json , analyze , verbose ) { stmt.strip ( ) .rstrip ( ' ; ' ) } ; '' A dictionary representing the query execution plan . drop table if exists comments ; `` `` '' A node in a query execution plan . '' '' '' `` `` '' A list of the node 's children . '' '' '' `` `` '' A dict of the node 's properties . '' '' '' with conn.cursor ( ) as cur : `` `` '' ) `` Actual Rows '' : int , populate with sample data assert qep.root [ 0 ] .plan [ `` Alias '' ] == `` comments '' assert qep.root [ 0 ] .plan [ `` Relation Name '' ] == `` stories '' `` `` '' Performs analyses on given queries , returning resultant QEPAnalysis . '' '' '' return self._qep [ `` Plan '' ] qep = parser ( `` select * from users where id = 1 or id = 2 '' ) self._conn : connection = conn or psycopg2.connect ( * args , * * kwargs ) postgresql = factories.postgresql ( `` postgresql_in_docker '' ) stmt : The query to execute . return self._node.__repr__ ( ) insert into stories ( name ) values ( 'story2 ' ) ; from psycopg2.extensions import connection from pytest_postgresql import factories `` Node Type '' : str , assert qep.plan [ `` Alias '' ] == `` comments '' assert qep.plan [ `` Node Type '' ] == `` Result '' Returns : def __repr__ ( self ) : assert qep.root [ 0 ] .plan [ `` Relation Name '' ] == `` users '' load= [ load_database ] , insert into users ( name ) values ( 'user2 ' ) ; def __getitem__ ( self , key : int ) - > `` QEPNode '' : `` Actual Startup Time '' : float , `` Plan Width '' : int , assert qep.plan [ `` Actual Rows '' ] == 1 raise ValueError ( f '' Expected 1 column , got { n } '' ) assert qep.root [ 0 ] .plan [ `` Relation Name '' ] == `` comments '' * args : Positional arguments to pass to cursor.execute ( ) . user=getenv ( `` POSTGRES_USER '' , `` postgres '' ) , class QEPNode : user_id integer references users ( id ) on delete cascade , def find ( self , pred : Callable [ [ node ] , bool ] ) - > list [ node ] :","['.gitattributes', 'qepparser.py', 'test_qepparser.py']",2022-10-13 10:05:14+00:00,2022-11-10 10:55:29+00:00,2022-10-11 17:32:29+03:00
37,3d6dec83450eb47b7c1c89380c7d32be851a2780,0.0004441581841092,0,qepparser needs to use SET constraint_exclusion = 'on ' before doing its queries . This makes # 6 trivial search for One-Time Filter 's from the QEP .,constraint_exclusion option for qepparser,Merge pull request # 97 from Project-C-SQL/fix/qepparser-crash,"if self.qep_analysis is None : return QEPAnalysis ( res [ 0 ] [ 0 ] [ 0 ] ) with self._conn.cursor ( ) as cur : raise ValueError ( f '' Expected 1 row , got { n } '' ) if ( n : = len ( res ) ) ! = 1 : return QEPAnalysis ( res [ 0 ] [ 0 ] [ 0 ] ) if ( n : = len ( res [ 0 ] ) ) ! = 1 : try : if ( t : = type ( res [ 0 ] [ 0 ] [ 0 ] ) ) ! = dict : self._conn.commit ( ) cur.execute ( `` set constraint_exclusion = on ; '' ) raise ValueError ( f '' Expected 1 item in column , got { n } '' ) if ( t : = type ( res [ 0 ] [ 0 ] [ 0 ] ) ) ! = dict : if qep_analysis_with_constraint_exclusion is None : cur.execute ( stmt , * args , * * kwargs ) if ( n : = len ( res ) ) ! = 1 : with self._conn.cursor ( ) as cur : if ( n : = len ( res [ 0 ] [ 0 ] ) ) ! = 1 : cur.execute ( `` set constraint_exclusion = off ; '' ) cur.execute ( `` set constraint_exclusion = on ; '' ) if ( n : = len ( res [ 0 ] [ 0 ] ) ) ! = 1 : if qep_analysis_without_constraint_exclusion is None : raise ValueError ( f '' Expected 1 row , got { n } '' ) raise ValueError ( f '' Expected dict in column , got { t } '' ) self._conn.rollback ( ) self._conn.commit ( ) self._conn.rollback ( ) cur.execute ( `` set constraint_exclusion = off ; '' ) cur.execute ( stmt , * args , * * kwargs ) except Exception as e : try : res = cur.fetchall ( ) raise ValueError ( f '' Expected 1 column , got { n } '' ) return None res = cur.fetchall ( ) raise ValueError ( f '' Expected 1 item in column , got { n } '' ) raise ValueError ( f '' Expected 1 column , got { n } '' ) stmt = `` explain ( format json , analyze , verbose ) '' + \ stmt = `` explain ( format json , analyze , verbose ) `` + \ if ( n : = len ( res [ 0 ] ) ) ! = 1 : except psycopg.Error as e : raise ValueError ( f '' Expected dict in column , got { t } '' )","['src/pg4n/implied_expression_checker.py', 'src/pg4n/qepparser.py', 'src/pg4n/subquery_order_by_checker.py']",2022-10-25 08:51:21+00:00,2022-11-05 11:28:49+00:00,2022-12-16 13:05:50+02:00
47,149f24e74104b324b62326453e7cbe12b53a5f5a,0.0011382474331185,0,,Detect compare different domains error ( e31 per Brass ),Merge pull request # 101 from Project-C-SQL/feat/maintenance-plan,"# # # Extending parsers Returns warning message if the sql has SUM/AVG ( DISTINCT ... ) , otherwise None Handle a user 's psql session transparently with select injections to psql output . Wildcards without LIKE ( Error 34 per Brass and Goldberg , 2005 ) ( ` EqWildcardChecker ` ) Returns an empty list if none found . Returns an empty list if no SQL statement is found . If found , returns a list of strings containing complete statement ( `` SELECT ... ; '' ) if flattened . Inconsistent expression ( Error 1 per Brass and Goldberg , 2005 ) ( ` InconsistentExpressionChecker ` ) # # # # ConfigReader Frontend handles user 's psql session completely transparently via ` PsqlWrapper ` , although also injecting insightful messages regarding user 's semantic errors into the terminal output stream . It parses user 's SQL queries via ` PsqlParser ` for consumption in the backend . otherwise None . Strange HAVING ( Error 32 per Brass and Goldberg , 2005 ) ( ` StrangeHavingChecker ` ) Expected to be deprecated when detecting multiple statements is implemented . ` PsqlParser ` uses ` pyparsing ` parser combinator library to provide parsing functions for SELECT in subquery uses no tuple variable of subquery ( Error 29 per Brass and Goldberg , 2005 ) ( ` SubquerySelectChecker ` ) Get query statements and their results , and sanitize them for syntactic analysis Pg4n only injects messages for the user , and is otherwise completely transparent . For this reason , usage is identical to ` psql ` usage . [ PostgreSQL : Documentation : 14 : psql ] ( https : //www.postgresql.org/docs/14/app-psql.html ) Comparison between different domains ( Error 31 per Brass and Goldberg , 2005 ) ( ` CmpDomainChecker ` ) # # Updating pg4n If improper parsing is suspected , turn ` PsqlParser.debug ` to ` True ` , that way all ` ParserException.explain ` s are saved into ` psqlparser.log ` . These exceptions are verbose , and will require fair amount of sifting . If improper interception by ` PsqlWrapper ` is suspected , turn ` PsqlWrapper.debug ` to ` True ` , to have current ` pyte ` display contents copied to ` pyte.screen ` on every update , and ` pexpect ` terminal control stream appended into ` psqlwrapper.log ` . Any wrapper issues are expected to be quite obtuse to fix , as they likely are ` pexpect ` or ` pyte ` library issues . # # # ErrorFormatter Returns warning message if the sql has equals operation to a string with For example : x = 10 AND x = 20 This psql output analysis program is built around three essential modules : * [ Psql wrapper interface ] ( ./interfaces.md # psqlwrapper ) pg4n # # PsqlParser Implied expression ( Table already enforces the given expression ) ( ` ImpliedExpressionChecker ` ) See API docs . ` parser ` is an implementation of PsqlParser interface . ` pyparsing ` documentation is available on [ Welcome to PyParsing  s documentation ! ] ( https : //pyparsing-docs.readthedocs.io/en/latest/ ) # # # Fixing parsing/interception bugs $ HOME/.config/pg4n.conf , and lastly from $ PWD/pg4n.conf , with each new value Does analysis for suspicous comparisons between different domains . # # # SQLParser # Interfaces This checker only finds a small subset of such expression , where postgresql # # # ` parse_for_a_new_prompt ( psql : str ) - > List [ str ] ` # # # # InconsistentExpressionChecker # # # SemanticRouter # # # PsqlWrapper # # Known limitations ` PsqlWrapper ` also checks ` psql ` version info and checks it against ` PsqlWrapper.supported_psql_versions ` . # # # Analysis modules # Program architecture Contains option values specied in the configuration files . Condition in the subquery can be moved up ( Error 30 per Brass and Goldberg , 2005 ) ( ` SubquerySelectChecker ` ) # General information Each Checker class must use this to format their warning messages . ` PsqlWrapper ` is responsible for spawning and intercepting the user-interfacing ` psql ` process . ` pexpect ` library allows both spawning and intercepting the terminal control stream . ` pyte ` library keeps track of current terminal display . Unified error formatting . Parsing rules common to more than 1 of these functions are listed in ` PsqlParser ` body , but otherwise rules are inside respective functions . parsing last SQL SELECT query in a string ( ` parse_last_stmt ` ) # # # Program configuration Also provides some utilities like finding all tables in a sql statement . # # # # StrangeHavingChecker ` PsqlConnInfo ` fetches PostgresSQL connection info by running a ` psql ` command with given arguments ( usually same arguments as with what the main ` psql ` process was called with ) . e.g. , comparing columns off type VARCHAR ( 20 ) and VARCHAR ( 50 ) Reads all configuration files and combines their option output into a ` ConfigValues ` class . The psql wrapper module has following requirements : Options in the configuration file are written like : `` option\_name value '' where value may be : true , 1 , yes , false , 0 , no Returns an empty list if no prompt is found . Returns prompt text ( `` dbname= > '' or `` dbname= # '' ) if found . # # # # SubquerySelectChecker # # Using pg4n Overall working logic is handled by ` _check_and_act_on_repl_output ` , where it can be seen that queries are checked for every time user presses Return . If ` PsqlParser ` finds an SQL SELECT query , it 's passed to ` SemanticRouter ` for further analysis , and any insightful message returned is saved for later . Once all query results have been printed , and a new prompt ( e.g ` .. = > ` ) is going to be printed next per ` latest_output ` parameter , the wrapper injects the returned message . If results included ` ERROR : ` .. ` ^ ` , it is sent to syntax error analysis , and any returned message will be injected immediately . ! [ Program architecture sketch ] ( ./architecture.jpg ) # # Semantic errors detected ` psql ` is the psql REPL log to be inspected . ` PsqlWrapper ` has a ` hook_syntax_f ` function parameter ( of type ` str - > str ` ) , which is called with ` PsqlParser.parse_syntax_error ` -produced string , ideally `` ERROR : ... ^ '' , which , to our understanding , will always include the whole result , and also the SQL query itself ( as caret will point to it ) , so it does not have to be parsed separately . A syntax error analysis component should then return a message string , and it will be displayed in exactly the same way as semantic error strings . # # # # EqWildcardChecker Binary files a/docs/architecture.jpg and /dev/null differ Parse for an empty prompt , usually to detect when a query evaluation has ended . # # # ` Wrapper ( db_name : str , hook_f : Callable [ str , str ] , parser : PsqlParser ) ` Returns a warning message if something was found , otherwise None . Returns warning message if there no column SELECTed in a subquery is # # # # SumDistinctChecker # # # # ConfigValues Parses a configuration file . introduced in latter files overriding the previous value . The configuration files are read in order from : /etc/pg4n.conf then from $ XDG\_CONFIG\_HOME/pg4n.conf , or if $ XDG\_CONFIG\_HOME is not set , from Most of the semantic analysis modules have been implemented by parsing the SQL with ` sqlglot ` . Only few of the Checker classes use the query evaluation plan ( QEP ) . program-architecture maintenance-plan checking if given string has a new prompt ( e.g ` = > ` ) ( ` output_has_new_prompt ` ) # # # # ConfigParser # # Installing pg4n ` hook_f ` is the function that the wrapper sends prettified user input & program output to , and from where it gets its helpful messages to inject before next prompt . To our knowledge , there are no interdependencies with the parser functions , so they should be able to be extended as needed , and new ones added . By default all warnings are enabled . Warnings can be disabled by warning type ( which can be found from every warning message 's end ) e.g . parsing ` psql -- version ` output for version number ( ` parse_psql_version ` ) Constructor is the only currently required interface . # # Backend should never give false positives , only false negatives . exposes that information via its query execution plan . Returns warning message if there exists ORDER BY in a subquery , ` pip install pg4n ` itself detects the inconsistent expression in its query optimizer and wild card character ( the ' % ' character ) , otherwise None . ` CmpDomains false ` Semantic error modules are expected to produce false negatives . Parse for the content between two prompts . Returns an empty list if there is no statement or there was an error . # # # QEPParser DISTINCT in SUM and AVG ( Error 33 per Brass and Goldberg , 2005 ) ( ` SumDistinctChecker ` ) parsing syntax errors ( ` ERROR : ` .. ` ^ ` ) ( ` parse_syntax_error ` ) ` pip install -- upgrade pg4n ` Transforms sql string into a syntax tree . # # PsqlWrapper # # # # SubqueryOrderByChecker # # # Implementing semantic analysis modules # Maintaining pg4n # # # # CmpDomainChecker not used in that subquery of its own columns , otherwise returns None . Returns warning message if there exists HAVING without a GROUP BY , otherwise None . Runs SQLParser , QEPParser and semantic error analysis modules ( as configured ) against given SQL query string . ` pexpect ` does not seem to handle all terminal traffic . ` pyte ` and user terminal occasionally disagree on contents when user uses ctrl-R to fetch past queries , which prevents screenscraping SQL query properly . ` pyte ` also disagrees on display contents when exiting a separate query results screen , but this has no impact on ` pg4n ` performance . # # # PsqlParser interfaces # # # PsqlConnInfo # # # Thoughts on syntax error analysis ORDER BY in a subquery ( ` SubqueryOrderByChecker ` ) checking for non-obvious Return presses ( ` output_has_magical_return ` ) # # # ` parse_first_found_stmt ( psql : str ) - > List [ str ] ` ` db_name ` is name of the database psql needs to access Inconsistent expression is some expression that is never true . Returns warning message if implied expression is detected , otherwise None . # # # # ImpliedExpressionChecker # # Frontend parsing a new prompt and everything that precedes it in a string , to allow easy message injection ( ` parse_new_prompt_and_rest ` ) This check gives misses some situations with redundant ORDER BY but","['docs/architecture.jpg', 'docs/architecture.md', 'docs/index.rst', 'docs/interfaces.md', 'docs/maintenance-plan.md', 'docs/pg4n.md', 'docs/program-architecture.md']",2022-11-04 12:12:28+00:00,2022-11-04 14:51:56+00:00,2022-12-16 18:54:08+02:00
47,bbd831ee1f05324f62486eca5ace30ed845111a7,0.0002208953519584,0,,Detect compare different domains error ( e31 per Brass ),Merge pull request # 77 from Project-C-SQL/feat/errfmt,"warning_msg = `` Warning : Possible use of '= ' instead of % for wildcard pattern [ pg4n : :EqWildcard ] '' formatter = ErrorFormatter ( warning , warning_name ) msg_header = f '' Warning : Comparison between different domains ( { domain1 } , { domain2 } ) [ pg4n : :CmpDomains ] \n '' warning_name = `` SumDistinct '' self.warning_msg = self.warning_msg + msg_header + underlined_query formatter = ErrorFormatter ( warning , warning_name ) from . qepparser import QEPAnalysis warning_name = `` EqWildcard '' warning_name = `` SubquerySelect '' ) self.warning_msg = formatter.format ( ) warning_name = `` StrangeHaving '' VT100_RESET = `` \x1b [ 0m '' warning = `` DISTINCT in SUM or AVG '' warning_name = `` CmpDomains '' warning_name = `` SurplusSemicolons '' warning_name = `` InnerOrderBy '' warning = `` ORDER BY in a subquery '' warning_msg = `` Warning : ORDER BY in a subquery [ pg4n : :InnerOrderBy ] '' warning_name = `` ImpliedExpression '' warning_msg = `` Warning : DISTINCT in SUM or AVG [ pg4n : :SumDistinct ] '' self.warning_name : str = warning_name warning_header = `` Warning : No column in subquery SELECT references its tables [ pg4n : :SubquerySelect ] \n '' warning_msg = formatter.format ( ) self.underlined_query : Optional [ str ] = underlined_query warning = `` Too many semicolons '' assert ( warning = `` No column in subquery SELECT references its tables '' formatter = ErrorFormatter ( warning , warning_name , underlined_query ) warning_msg.find ( warning ) ! = -1 self.warning_msg : str = warning_msg warning_msg += formatter.format ( ) warning = `` HAVING without GROUP BY '' from typing import Optional underlined_query : Optional [ str ] = None , assert warning_msg.find ( warning ) ! = -1 and warning_msg.find ( warning_name ) ! = -1 def __init__ ( warning = `` Too many parentheses '' warning_name = `` SurplusParentheses '' from .qepparser import QEPAnalysis FROM customers ) : class ErrorFormatter : and warning_msg.find ( warning_name ) ! = -1 warning = f '' Comparison between different domains ( { domain1 } , { domain2 } ) '' Returns a formatted error message . return base_msg warning = `` Found impossible comparison due to column/table constraints '' def test_format ( ) : self , formatter = ErrorFormatter ( warning , warning_name , underlined_query ) from .errfmt import ErrorFormatter underlined_query = f '' '' '' SELECT * from .. errfmt import ErrorFormatter warning_name : str , base_msg = f '' Warning : { self.warning_msg } [ pg4n : : { self.warning_name } ] '' warning_msg = `` Warning : HAVING without GROUP BY [ pg4n : :StrangeHaving ] '' if self.underlined_query : warning_msg = `` Warning : Found impossible comparison due to column/table constraints [ pg4n : :ImpliedExpression ] '' warning = `` Possible use of '= ' instead of LIKE for wildcard pattern '' def format ( self ) - > str : `` `` '' and warning_msg.find ( underlined_query ) ! = -1 VT100_UNDERLINE = `` \x1b [ 4m '' warning_msg : str , warning_msg += warning_header + underlined_query { VT100_UNDERLINE } WHERE type ' C ' { VT100_RESET } = 1 OR 100 = 100 ; '' '' '' return base_msg + f '' \n { self.underlined_query } '' warning_msg = formatter.format ( )","['src/pg4n/cmp_domain_checker.py', 'src/pg4n/eq_wildcard_checker.py', 'src/pg4n/errfmt.py', 'src/pg4n/implied_expression_checker.py', 'src/pg4n/strange_having_checker.py', 'src/pg4n/subquery_orderby_checker.py', 'src/pg4n/subquery_select_checker.py', 'src/pg4n/sum_distinct_checker.py', 'src/pg4n/test/test_errfmt.py']",2022-11-04 12:12:28+00:00,2022-11-04 14:51:56+00:00,2022-11-21 12:21:55+02:00
55,f0c8da964af2e49927972c237584994b8aca901b,0.0002287726238137,0,,Detect subquery that does n't use its select columns ( e29 per Brass ),Merge pull request # 57 from Project-C-SQL/feat/subquery-orderby,"insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 221 , 487.39 , 227 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 13 , 'Marion ' , 'Penelli ' , ' B ' , 'Adaline ' ) ; ORDER BY o.customer_id ) ; '' '' '' insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 14 , 586.06 , 181 ) ; # Gets all the non-root select statements insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 153 , 350.78 , 247 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 5 , 'Callida ' , 'Tomasello ' , ' B ' , 'Abiel ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 50 , 306.71 , 235 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 10 , 414.55 , 234 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 246 , 510.74 , 188 ) ; sql_statement = SQL_NESTED_SUBQUERY_INNER_ORDER insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 78 , 569.4 , 99 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 93 , 452.63 , 115 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 218 , 389.51 , 177 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 166 , 95.01 , 189 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 97 , 313.39 , 241 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 119 , 579.12 , 43 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 176 , 'Marylou ' , 'Guilloton ' , ' C ' , 'Bridget ' ) ; from .. subquery_orderby_checker import SubqueryOrderByChecker import subprocess ORDER BY o.customer_id ) OR insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 23 , 'Jeanette ' , 'Fincher ' , ' B ' , 'Adriane ' ) ; sqlglot.exp.Select ) ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 132 , 'Olympe ' , 'Faber ' , ' B ' , 'Barbery ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 233 , 87.21 , 179 ) ; `` `` '' insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 196 , 'Louisa ' , 'Matasov ' , ' B ' , 'Carmon ' ) ; return None insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 42 , 561.85 , 222 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 78 , 'Matilde ' , 'Froome ' , ' B ' , 'Angelica ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 159 , 281.36 , 198 ) ; from . qepparser import QEPAnalysis sql_statement = SQL_OUTER_ORDER_WITH_INNER_ORDER WHERE EXISTS ( SELECT * insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 20 , 207.6 , 9 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 216 , 388.15 , 142 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 4 , 144.14 , 157 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 192 , 206.39 , 151 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 24 , 538.88 , 38 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 77 , 'Maegan ' , 'Wheldon ' , ' C ' , 'Angela ' ) ; import pytest insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 82 , 106.39 , 237 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 29 , 'Dawna ' , 'Knipe ' , ' C ' , 'Alanson ' ) ; SQL_OUTER_ORDER_WITHOUT_INNER_ORDER = \ assert warning_msg is not None CUSTOMERS_TABLE_NAME = `` inner_orderby_test_table_customers '' insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 242 , 356.69 , 244 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 210 , 332.45 , 47 ) ; print ( `` SQL_OUTER_ORDER_WITHOUT_INNER_ORDER '' ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 63 , 'Gratia ' , 'Moss ' , ' B ' , 'Althea ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 187 , 'Donall ' , 'Casolla ' , ' B ' , 'Calvin ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 32 , 'Aubrie ' , 'Lockitt ' , ' C ' , 'Albert ' ) ; `` EXPLAIN ANALYZE `` + sql_statement ] ) insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 176 , 22.8 , 175 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 245 , 327.9 , 212 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 169 , 'Elsbeth ' , 'Nucciotti ' , ' B ' , 'Bradley ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 37 , 'Talbot ' , 'Keddey ' , ' B ' , 'Aleva ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 237 , 293.23 , 140 ) ; assert warning_msg is None insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 229 , 89.34 , 147 ) ; WHERE c.customer_id = o.customer_id insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 56 , 'Kaitlin ' , 'Payle ' , ' B ' , 'Allyson ' ) ; WHERE c.customer_id = o.customer_id ) ; '' '' '' insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 44 , 537.56 , 2 ) ; should never give false positives , only false negatives . insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 188 , 'Ferguson ' , 'Mackriell ' , ' B ' , 'Cameron ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 204 , 212.04 , 203 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 122 , 'Myrlene ' , 'Worcs ' , ' B ' , 'Augusta ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 183 , 'Harvey ' , 'Skinn ' , ' B ' , 'Caleb ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 226 , 212.04 , 28 ) ; has_orderby = self.parsed_sql.find ( exp.Order ) is not None insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 46 , 362.72 , 240 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 201 , 411.07 , 202 ) ; parsed_sql = sqlparser.parse ( sql_statement ) if not has_inner_orderby : order_id INT insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 242 , 'Brenden ' , 'Simmons ' , ' B ' , 'Clarence ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 52 , 'Gerrilee ' , 'Ackland ' , ' B ' , 'Allan ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 119 , 'Gregg ' , 'Lazenbury ' , ' B ' , 'Aubrey ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 171 , 'Fredrick ' , 'Matuszynski ' , ' C ' , 'Breanna ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 137 , 'Lucilia ' , 'Bentick ' , ' C ' , 'Bartholomew ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 11 , 88.19 , 50 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 162 , 'Jessee ' , 'List ' , ' B ' , 'Billy ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 14 , 'Davon ' , 'Burris ' , ' C ' , 'Addison ' ) ; , order_total_eur DECIMAL ( 6,2 ) NOT NULL from .. qepparser import QEPParser insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 32 , 331.93 , 144 ) ; # False negative : dont assert insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 83 , 'Wolf ' , 'Brenton ' , ' B ' , 'Annette ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 246 , 'Albert ' , 'Heimann ' , ' B ' , 'Cleatus ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 189 , 164.91 , 68 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 240 , 384.87 , 107 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 144 , 504.73 , 154 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 127 , 'Rhoda ' , 'Kurton ' , ' C ' , 'Avarilla ' ) ; FROM ( SELECT * insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 28 , 'Nanice ' , 'MacMaster ' , ' B ' , 'Alan ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 151 , 221.16 , 212 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 148 , 203.36 , 180 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 169 , 552.88 , 241 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 57 , 'Vita ' , 'Dunnett ' , ' B ' , 'Allyssa ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 214 , 'Chalmers ' , 'Britton ' , ' C ' , 'Celinda ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 70 , 596.2 , 221 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 12 , 'Tiffi ' , 'Riolfo ' , ' C ' , 'Ada ' ) ; import sys insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 173 , 'Kristopher ' , 'Mackelworth ' , ' B ' , 'Brenda ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 7 , 183.92 , 236 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 219 , 594.84 , 121 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 130 , 'Rora ' , 'Adcock ' , ' C ' , 'Babs ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 162 , 168.92 , 27 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 89 , 556.68 , 74 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 183 , 546.08 , 88 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 118 , 23.96 , 195 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 18 , 'Odie ' , 'Rowling ' , ' C ' , 'Adele ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 30 , 'Colin ' , 'Jansie ' , ' C ' , 'Alastair ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 177 , 'Genvieve ' , 'Marthen ' , ' B ' , 'Brittany ' ) ; print ( parsed_sql ) insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 150 , 439.75 , 18 ) ; import psycopg insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 102 , 'Ricca ' , 'Rupprecht ' , ' B ' , 'Arlene ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 227 , 189.25 , 230 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 206 , 226.62 , 228 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 186 , 561.85 , 156 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 1 , 535.36 , 111 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 212 , 179.55 , 180 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 103 , 14.83 , 183 ) ; SQL_OUTER_ORDER_WITH_INNER_ORDER = \ insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 171 , 175.72 , 249 ) ; STATEMENT_WITHOUT_OUTER_ORDER = \ insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 128 , 'Jere ' , 'Cometti ' , ' B ' , 'Azariah ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 137 , 417.16 , 215 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 10 , 'Sonnie ' , 'Kelling ' , ' B ' , 'Abram ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 140 , 'Suki ' , 'Flinn ' , ' B ' , 'Bea ' ) ; SELECT * insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 104 , 97.04 , 11 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 115 , 351.68 , 153 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 30 , 435.57 , 105 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 208 , 344.91 , 150 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 239 , 327.06 , 34 ) ; _test ( True , STATEMENT_WITHOUT_OUTER_ORDER , db_name ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 91 , 'Bobby ' , 'Fortesquieu ' , ' B ' , 'Aquilla ' ) ; FROM ( SELECT * insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 121 , 'Clywd ' , 'Stokey ' , ' B ' , 'August ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 28 , 87.44 , 1 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 8 , 424.8 , 244 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 109 , 170.82 , 206 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 181 , 150.37 , 69 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 64 , 'Dyan ' , 'Crosbie ' , ' B ' , 'Alverta ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 194 , 328.76 , 41 ) ; db_name = str ( sys.argv [ 1 ] ) insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 121 , 132.25 , 50 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 123 , 'Lyon ' , 'Nolleau ' , ' C ' , 'Augustina ' ) ; `` `` '' insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 248 , 321.97 , 195 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 201 , 'Arv ' , 'Spawforth ' , ' B ' , 'Carrie ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 221 , 'Cassondra ' , 'Mattingson ' , ' B ' , 'Chesley ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 96 , 'Tiertza ' , 'Bunford ' , ' C ' , 'Archibald ' ) ; from . import sqlparser insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 202 , 'Sonja ' , 'Pentycross ' , ' B ' , 'Carthaette ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 234 , 'Cayla ' , 'Statter ' , ' B ' , 'Christopher ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 146 , 'Dunstan ' , 'Cressey ' , ' B ' , 'Bella ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 240 , 'Britte ' , 'Muge ' , ' B ' , 'Clara ' ) ; USAGE = `` usage : orderby.py < db_name > '' insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 156 , 'Allistir ' , 'Frary ' , ' C ' , 'Beth ' ) ; if __name__ == `` __main__ '' : if expected ! = result : insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 88 , 210.95 , 158 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 117 , 'Marysa ' , 'Wadman ' , ' C ' , 'Asenath ' ) ; FROM orders o ORDER BY o.customer_id insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 133 , 'Clementia ' , 'Fergusson ' , ' B ' , 'Barbie ' ) ; print ( f '' expected : { expected } , result : { str ( result ) } '' ) ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 237 , 'Jeramie ' , 'Gallehock ' , ' C ' , 'Cinderella ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 161 , 184.39 , 94 ) ; warning_msg = `` Warning : ORDER BY in a subquery [ pg4n : :InnerOrderBy ] '' insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 130 , 575.58 , 235 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 178 , 'Rogers ' , 'Plose ' , ' B ' , 'Brittney ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 42 , 'Pyotr ' , 'Feldhorn ' , ' C ' , 'Alexis ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 209 , 'Dulcea ' , 'Akister ' , ' C ' , 'Cathleen ' ) ; CREATE TABLE { CUSTOMERS_TABLE_NAME } ( insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 66 , 454.41 , 11 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 23 , 236.48 , 51 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 41 , 158.78 , 145 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 43 , 133.73 , 196 ) ; import sqlglot insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 59 , 'Lin ' , 'Race ' , ' B ' , 'Almina ' ) ; ORDER BY o2.customer_id ) AS o STATEMENT_MULTIPLE_INNER_ORDERS = \ insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 182 , 478.47 , 70 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 54 , 591.44 , 145 ) ; # Does not matter all only here so we can get a connection insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 79 , 94.87 , 194 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 128 , 415.86 , 243 ) ; This check gives misses some situations with redundant ORDER BY but insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 160 , 'Patti ' , 'Louis ' , ' C ' , 'Biddie ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 166 , 'Angelo ' , 'Vanstone ' , ' C ' , 'Boetius ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 98 , 'Elfreda ' , 'Tome ' , ' C ' , 'Ariadne ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 136 , 411.87 , 10 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 157 , 477.53 , 205 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 15 , 47.79 , 248 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 77 , 335.23 , 149 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 57 , 349.14 , 58 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 87 , 'Nanette ' , 'McElwee ' , ' B ' , 'Antoinette ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 48 , 'Marve ' , 'Eykel ' , ' C ' , 'Alicia ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 61 , 'Blisse ' , 'Dillway ' , ' C ' , 'Alonzo ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 167 , 547.07 , 197 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 45 , 'Seymour ' , 'Mayer ' , ' B ' , 'Alfreda ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 112 , 38.97 , 239 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 223 , 'Annice ' , 'Haynes ' , ' B ' , 'Chet ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 24 , 'Jacinthe ' , 'Kleeman ' , ' B ' , 'Adrienne ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 62 , 418.98 , 60 ) ; FROM customers c insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 27 , 137.86 , 21 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 170 , 539.11 , 92 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 67 , 550.21 , 63 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 181 , 'Daria ' , 'Wistance ' , ' C ' , 'Caitlyn ' ) ; FROM orders o2 insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 26 , 590.52 , 50 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 170 , 'Bard ' , 'Shaw ' , ' C ' , 'Brady ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 45 , 46.05 , 177 ) ; ) ; conn : Connection = psycopg.connect ( * * kwargs ) insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 49 , 376.9 , 89 ) ; ORDER BY o2.customer_id ) AS o insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 19 , 107.53 , 94 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 92 , 'Raven ' , 'Eilles ' , ' C ' , 'Ara ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 139 , 'Kelsi ' , 'Suddell ' , ' C ' , 'Bazaleel ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 141 , 'Jacinta ' , 'Villiers ' , ' B ' , 'Beatrice ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 234 , 254.56 , 98 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 48 , 199.52 , 234 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 68 , 73.27 , 189 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 245 , 'Holly ' , 'Roy ' , ' C ' , 'Claudia ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 232 , 330.85 , 204 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 99 , 'Phineas ' , 'Yuryaev ' , ' B ' , 'Arielle ' ) ; ) OR EXISTS ( insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 114 , 339.9 , 108 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 142 , 509.25 , 190 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 213 , 'Rubin ' , 'Lunney ' , ' B ' , 'Celeste ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 41 , 'Reilly ' , 'Kennler ' , ' B ' , 'Alexandria ' ) ; SQL_WITHOUT_OUTER_ORDER = \ insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 76 , 'Ardys ' , 'Currm ' , ' B ' , 'Andriane ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 202 , 99.52 , 171 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 159 , 'Carilyn ' , 'Vinecombe ' , ' B ' , 'Bezaleel ' ) ; lambda x : x.parent is not None , DROP TABLE IF EXISTS { ORDERS_TABLE_NAME } ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 75 , 238.65 , 203 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 39 , 42.62 , 95 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 129 , 'Ashla ' , 'De-Ville ' , ' C ' , 'Bab ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 82 , 'Abey ' , 'Darridon ' , ' C ' , 'Anne ' ) ; STATEMENT_NESTED_SUBQUERY_INNER_ORDER = \ insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 248 , 'Norby ' , 'Biernacki ' , ' C ' , 'Clementine ' ) ; otherwise None . insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 22 , 'Grazia ' , 'Syne ' , ' C ' , 'Adrian ' ) ; sql.find_all ( insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 153 , 'Alfy ' , 'McCahill ' , ' B ' , 'Bertha ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 214 , 520.52 , 98 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 63 , 542.48 , 52 ) ; ORDER BY c.customer_id ; customer_id INT insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 17 , 'Carlyle ' , 'Zimek ' , ' B ' , 'Adelbert ' ) ; return SqlParser ( db_connection=postgresql ) insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 165 , 84.61 , 1 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 142 , 'Elfrieda ' , 'Cleary ' , ' C ' , 'Becca ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 154 , 'Conney ' , 'Riteley ' , ' C ' , 'Bertram ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 180 , 'Leonelle ' , 'Chiommienti ' , ' B ' , 'Caitlin ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 61 , 343.91 , 223 ) ; f '' '' '' self.qep_analysis.root.rfindval ( `` Node Type '' , `` Sort '' ) ) > 0 insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 224 , 'Dayle ' , 'Eirwin ' , ' B ' , 'Chick ' ) ; with conn.cursor ( ) as cur : insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 190 , 'Kara ' , 'Backs ' , ' B ' , 'Campbell ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 220 , 'Kylen ' , 'Bewicke ' , ' B ' , 'Cheryl ' ) ; qep = subprocess.check_output ( [ `` psql '' , `` -X '' , `` -d '' , db_name , `` -c '' , insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 113 , 305.06 , 123 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 2 , 'Tomlin ' , 'Nozzolinii ' , ' B ' , 'Abbigail ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 31 , 394.48 , 62 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 141 , 183.27 , 44 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 89 , 'Nickie ' , 'Bloss ' , ' C ' , 'Antonio ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 243 , 209.34 , 31 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 157 , 'Noach ' , 'MacRitchie ' , ' C ' , 'Bethena ' ) ; WHERE EXISTS ( insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 191 , 'Frankie ' , 'Canny ' , ' B ' , 'Candace ' ) ; from pytest_postgresql import factories , fname VARCHAR ( 50 ) NOT NULL insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 11 , 'Amby ' , 'Ligoe ' , ' C ' , 'Absalom ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 185 , 505.7 , 49 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 250 , 'Langston ' , 'Prosser ' , ' C ' , 'Clifford ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 126 , 'Lilllie ' , 'Annis ' , ' C ' , 'Aurelia ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 51 , 'Kennan ' , 'Burstowe ' , ' B ' , 'Alixandra ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 3 , 189.43 , 19 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 188 , 495.68 , 39 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 163 , 'Gerhardt ' , 'Simcock ' , ' B ' , 'Blanche ' ) ; FROM { ORDERS_TABLE_NAME } o insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 123 , 370.87 , 115 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 74 , 63.02 , 117 ) ; factory = factories.postgresql_proc ( insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 191 , 183.55 , 142 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 116 , 292.86 , 97 ) ; parsed_sql = sql_parser.parse_one ( sql_statement ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 71 , 'Cynthie ' , 'Rouby ' , ' B ' , 'Anastasia ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 47 , 'Tracey ' , 'Sauvan ' , ' B ' , 'Alice ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 129 , 426.3 , 136 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 131 , 255.66 , 127 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 233 , 'Tibold ' , 'Sleigh ' , ' C ' , 'Christoph ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 249 , 'Rhoda ' , 'Leheude ' , ' C ' , 'Cliff ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 146 , 184.13 , 22 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 16 , 330.92 , 130 ) ; ORDERS_TABLE_NAME = `` inner_orderby_test_table_orders '' insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 65 , 'Glenna ' , 'Alastair ' , ' C ' , 'Alyssa ' ) ; cur.execute ( insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 225 , 'Egbert ' , 'Vasyunin ' , ' B ' , 'Chloe ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 197 , 'Missie ' , 'Fealty ' , ' C ' , 'Carol ' ) ; from .. sqlparser import SqlParser insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 25 , 83.54 , 79 ) ; assert checker is not None insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 84 , 'Birk ' , 'Malling ' , ' C ' , 'Annie ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 122 , 406.1 , 80 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 213 , 329.78 , 105 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 86 , 'Lauren ' , 'Tolworth ' , ' B ' , 'Anthony ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 90 , 169.25 , 30 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 103 , 'Ede ' , 'Golden of Ireland ' , ' C ' , 'Armanda ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 37 , 322.11 , 41 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 79 , 'Preston ' , 'Groves ' , ' B ' , 'Angelina ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 179 , 453.95 , 43 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 200 , 592.16 , 137 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 139 , 441.16 , 97 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 124 , 'Penelope ' , 'Quadling ' , ' C ' , 'Augustine ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 209 , 203.86 , 244 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 124 , 552.02 , 191 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 212 , 'Annecorinne ' , 'Soles ' , ' B ' , 'Cedric ' ) ; result = has_subquery_order_by ( parsed_sql , qep ) insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 56 , 501.06 , 129 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 90 , 'Forest ' , 'Trim ' , ' B ' , 'Appoline ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 134 , 'Georgetta ' , 'Crossley ' , ' B ' , 'Barnabas ' ) ; print ( `` SQL_OUTER_ORDER_WITH_INNER_ORDER '' ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 168 , 'Melicent ' , 'Cheston ' , ' B ' , 'Bradford ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 227 , 'Jeralee ' , 'Atwill ' , ' C ' , 'Christa ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 152 , 'Towny ' , 'Middell ' , ' B ' , 'Bert ' ) ; def load_database ( * * kwargs ) : def sql_parser ( postgresql : Connection ) : insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 62 , 'Seline ' , 'McGray ' , ' B ' , 'Alphinias ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 70 , 'Carmela ' , 'Sedgeworth ' , ' C ' , 'Amos ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 148 , 'Lidia ' , 'Quinane ' , ' C ' , 'Benjamin ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 243 , 'Hannah ' , 'Mattheis ' , ' C ' , 'Clarinda ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 241 , 296.03 , 169 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 69 , 266.3 , 39 ) ; ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 238 , 'Gregor ' , 'Crinion ' , ' B ' , 'Cindy ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 117 , 23.13 , 46 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 85 , 'Brig ' , 'Triswell ' , ' C ' , 'Anselm ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 109 , 'Marquita ' , 'Impy ' , ' B ' , 'Aron ' ) ; CREATE TABLE { ORDERS_TABLE_NAME } ( insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 132 , 488.95 , 234 ) ; , type CHAR ( 1 ) NOT NULL insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 84 , 396.02 , 111 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 87 , 441.16 , 191 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 229 , 'Melessa ' , 'MacAleese ' , ' C ' , 'Christiana ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 231 , 51.77 , 118 ) ; self.qep_analysis : QEPAnalysis = qep_analysis _test ( False , STATEMENT_OUTER_ORDER_WITHOUT_INNER_ORDER , db_name ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 19 , 'Daphne ' , 'Bullen ' , ' B ' , 'Adeline ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 134 , 296.72 , 222 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 133 , 499.73 , 235 ) ; print ( `` SQL_MULTIPLE_INNER_ORDERS '' ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 204 , 'Cassy ' , 'Pearcehouse ' , ' C ' , 'Casper ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 17 , 302.31 , 225 ) ; f '' '' '' qep = bytes.decode ( qep ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 195 , 'Dewey ' , 'Bottom ' , ' C ' , 'Carmelo ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 80 , 'Petey ' , 'Colloby ' , ' B ' , 'Ann ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 180 , 452.67 , 234 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 140 , 297.41 , 101 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 228 , 'Rudd ' , 'Ames ' , ' B ' , 'Christian ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 238 , 448.86 , 16 ) ; ) sql_statement = SQL_OUTER_ORDER_WITHOUT_INNER_ORDER insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 199 , 376.5 , 53 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 172 , 'Pammi ' , 'Codling ' , ' B ' , 'Breeanna ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 110 , 'Donall ' , 'Labrenz ' , ' B ' , 'Artelepsa ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 250 , 367.56 , 214 ) ; '' '' '' ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 111 , 'Torey ' , 'Sessuns ' , ' B ' , 'Artemus ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 25 , 'Neely ' , 'Merrydew ' , ' B ' , 'Agatha ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 244 , 'Katrine ' , 'Janiak ' , ' B ' , 'Clarissa ' ) ; warning_msg = checker.check ( ) # finds more warnings than postgresql . insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 195 , 504.28 , 117 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 131 , 'Ive ' , 'Matches ' , ' B ' , 'Barbara ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 161 , 'Barron ' , 'Dishmon ' , ' B ' , 'Bill ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 12 , 591.72 , 143 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 55 , 'Terrill ' , 'Syde ' , ' B ' , 'Allison ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 187 , 271.52 , 242 ) ; EXISTS ( SELECT * insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 222 , 416.65 , 59 ) ; from psycopg import Connection insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 100 , 424.83 , 50 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 241 , 'Sigismund ' , 'Mowsdill ' , ' B ' , 'Clare ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 193 , 449.91 , 213 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 210 , 'Pamelina ' , 'Vittery ' , ' C ' , 'Cathy ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 178 , 563.08 , 161 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 156 , 130.63 , 188 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 126 , 384.61 , 226 ) ; qep_analysis = qep_parser ( sql_statement ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 106 , 'Merrily ' , 'Coundley ' , ' C ' , 'Arminda ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 196 , 259.0 , 244 ) ; return QEPParser ( conn=postgresql ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 192 , 'Dudley ' , 'Vesco ' , ' B ' , 'Carlotta ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 113 , 'Dania ' , 'Foxton ' , ' C ' , 'Arthusa ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 211 , 399.2 , 138 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 98 , 177.22 , 86 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 247 , 'Dulcie ' , 'Crutchley ' , ' B ' , 'Clement ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 164 , 'Abel ' , 'Bezants ' , ' C ' , 'Bob ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 154 , 291.52 , 54 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 35 , 389.81 , 218 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 164 , 193.39 , 169 ) ; SQL_MULTIPLE_INNER_ORDERS = \ insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 21 , 'Nady ' , 'Lempertz ' , ' B ' , 'Adolphus ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 244 , 273.35 , 153 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 215 , 'Nollie ' , 'Jemmett ' , ' B ' , 'Charity ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 95 , 'Amandie ' , 'Botham ' , ' B ' , 'Araminta ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 27 , 'Callean ' , 'Werlock ' , ' C ' , 'Aileen ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 172 , 15.3 , 30 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 105 , 'Cary ' , 'Sells ' , ' C ' , 'Armilda ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 13 , 503.52 , 216 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 136 , 'Aretha ' , 'Arias ' , ' C ' , 'Bart ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 3 , 'Christen ' , 'Culley ' , ' C ' , 'Abednego ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 135 , 'Janenna ' , 'McCamish ' , ' C ' , 'Barney ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 15 , 'Zachary ' , 'Faloon ' , ' C ' , 'Adela ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 102 , 158.53 , 220 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 71 , 175.29 , 115 ) ; ORDER BY c.customer_id ; '' '' '' insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 93 , 'Sashenka ' , 'Fedorski ' , ' C ' , 'Arabella ' ) ; # This check still gives false negatives so we intentionally do n't test for insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 198 , 120.47 , 95 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 152 , 291.54 , 10 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 106 , 236.57 , 4 ) ; class SubqueryOrderByChecker : conn.commit ( ) insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 92 , 156.72 , 192 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 76 , 281.92 , 183 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 107 , 'Celisse ' , 'Rubra ' , ' B ' , 'Arminta ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 34 , 'Lorens ' , 'Buzin ' , ' C ' , 'Aldo ' ) ; self.parsed_sql : exp.Expression = parsed_sql SELECT * _test ( True , STATEMENT_OUTER_ORDER_WITH_INNER_ORDER , db_name ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 116 , 'Annmarie ' , 'Errichelli ' , ' B ' , 'Asaph ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 115 , 'Shirl ' , 'Pilpovic ' , ' C ' , 'Asahel ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 225 , 26.43 , 228 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 46 , 'Mechelle ' , 'Vinick ' , ' B ' , 'Algernon ' ) ; CHECK ( type IN ( ' C ' , ' B ' ) ) -- C = customer , B = business exit ( 1 ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 38 , 'Web ' , 'Catterill ' , ' B ' , 'Alex ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 224 , 293.35 , 186 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 54 , 'Malchy ' , 'Hearty ' , ' B ' , 'Allisandra ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 217 , 'Lucy ' , 'Durtnell ' , ' C ' , 'Charlie ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 94 , 'Halimeda ' , 'Freak ' , ' B ' , 'Arabelle ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 9 , 519.43 , 175 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 230 , 'Cordell ' , 'Bineham ' , ' B ' , 'Christiano ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 75 , 'Erma ' , 'Cranstone ' , ' B ' , 'Andrew ' ) ; DROP TABLE IF EXISTS { CUSTOMERS_TABLE_NAME } ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 184 , 380.46 , 98 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 68 , 'Leisha ' , 'Darlington ' , ' C ' , 'Ambrose ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 219 , 'Adriane ' , 'Ccomini ' , ' B ' , 'Chauncey ' ) ; , sname VARCHAR ( 50 ) NOT NULL insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 59 , 141.8 , 118 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 236 , 'Garnette ' , 'Tabrett ' , ' C ' , 'Cicely ' ) ; STATEMENT_OUTER_ORDER_WITHOUT_INNER_ORDER = \ , FOREIGN KEY ( customer_id ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 43 , 'Belle ' , 'Barsham ' , ' B ' , 'Alfonse ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 145 , 'Adena ' , 'Wenham ' , ' C ' , 'Belinda ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 197 , 529.63 , 46 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 39 , 'Tabbie ' , 'Glison ' , ' B ' , 'Alexander ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 33 , 140.92 , 236 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 29 , 217.18 , 124 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 80 , 17.1 , 21 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 96 , 311.78 , 173 ) ; has_sort_node = len ( insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 185 , 'Tanitansy ' , 'Headington ' , ' C ' , 'Calista ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 120 , 'Corinna ' , 'Pyburn ' , ' B ' , 'Audrey ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 33 , 'Amble ' , 'Jewes ' , ' B ' , 'Alberta ' ) ; STATEMENT_OUTER_ORDER_WITH_INNER_ORDER = \ , nickname VARCHAR ( 20 ) NOT NULL insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 165 , 'Angele ' , 'Wildbore ' , ' C ' , 'Bobby ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 108 , 'Janene ' , 'Motten ' , ' C ' , 'Arnold ' ) ; def __init__ ( self , parsed_sql : exp.Expression , qep_analysis : QEPAnalysis ) : def has_subquery_order_by ( sql : sqlglot.exp.Expression , qep : str ) - > bool : Returns warning message if there exists ORDER BY in a subquery , insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 107 , 23.63 , 179 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 168 , 137.02 , 109 ) ; has_inner_orderby = has_orderby and not has_sort_node insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 6 , 'Daisey ' , 'Hamill ' , ' B ' , 'Abigail ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 167 , 'Ninnette ' , 'Steere ' , ' C ' , 'Brad ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 69 , 'Maryjo ' , 'Pink ' , ' C ' , 'Amelia ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 50 , 'Anne-marie ' , 'Mounsie ' , ' B ' , 'Alison ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 151 , 'Prentiss ' , 'Filby ' , ' B ' , 'Berney ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 231 , 'Calhoun ' , 'BoHlingolsen ' , ' C ' , 'Christina ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 49 , 'Theodosia ' , 'Rosson ' , ' B ' , 'Aline ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 220 , 367.15 , 163 ) ; print ( `` SQL_NESTED_SUBQUERY_INNER_ORDER '' ) insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 99 , 354.37 , 66 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 51 , 244.27 , 119 ) ; SQL_NESTED_SUBQUERY_INNER_ORDER = \ insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 158 , 'Anett ' , 'Hercules ' , ' B ' , 'Beverly ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 26 , 'Jenica ' , 'Martina ' , ' C ' , 'Agnes ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 175 , 161.61 , 58 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 72 , 539.87 , 62 ) ; checker = SubqueryOrderByChecker ( parsed_sql , qep_analysis ) insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 203 , 545.33 , 116 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 21 , 471.12 , 179 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 138 , 223.81 , 183 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 40 , 33.89 , 23 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 101 , 'Hamilton ' , 'Pellew ' , ' B ' , 'Arizona ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 88 , 'Sansone ' , 'Copsey ' , ' C ' , 'Antonia ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 111 , 490.85 , 191 ) ; Does not use the qep so far . import sqlglot.expressions as exp insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 232 , 'Maritsa ' , 'Cowpland ' , ' C ' , 'Christine ' ) ; subqueries = filter ( insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 163 , 61.42 , 69 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 247 , 123.55 , 179 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 60 , 'Sibyl ' , 'Thoms ' , ' C ' , 'Almira ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 236 , 485.18 , 167 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 83 , 451.45 , 203 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 193 , 'Brucie ' , 'Coning ' , ' C ' , 'Carlton ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 228 , 542.3 , 42 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 127 , 451.77 , 17 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 120 , 454.18 , 214 ) ; sql_statement = SQL_WITHOUT_OUTER_ORDER insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 174 , 'Carolyn ' , 'Quinlan ' , ' C ' , 'Brian ' ) ; sql_statement = SQL_MULTIPLE_INNER_ORDERS insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 199 , 'Matilda ' , 'Malenoir ' , ' C ' , 'Caroline ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 179 , 'Daphne ' , 'Kells ' , ' C ' , 'Broderick ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 9 , 'Lester ' , 'Markus ' , ' C ' , 'Abraham ' ) ; postgresql = factories.postgresql ( `` factory '' ) insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 143 , 239.98 , 109 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 53 , 592.15 , 207 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 7 , 'Lorin ' , 'Dollimore ' , ' C ' , 'Abijah ' ) ; # TODO : More sophisticated check that inspects self.parsed_sql and , customer_id INT NOT NULL insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 55 , 391.93 , 128 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 1 , 'Josi ' , 'Grimsell ' , ' B ' , 'Aaron ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 175 , 'Davy ' , 'Blomefield ' , ' B ' , 'Brianna ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 118 , 'Hermy ' , 'Whieldon ' , ' B ' , 'Ashley ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 44 , 'Buffy ' , ' O '' Cridigan ' , ' B ' , 'Alfred ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 177 , 334.0 , 167 ) ; def check ( self ) - > Optional [ str ] : insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 86 , 537.64 , 201 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 85 , 404.96 , 79 ) ; _test ( True , STATEMENT_NESTED_SUBQUERY_INNER_ORDER , db_name ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 53 , 'Riva ' , 'Scawen ' , ' C ' , 'Allen ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 249 , 491.05 , 63 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 105 , 107.29 , 12 ) ; from typing import Optional insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 223 , 200.44 , 47 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 73 , 144.33 , 52 ) ; , PRIMARY KEY ( customer_id ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 74 , 'Giffy ' , 'Cottee ' , ' C ' , 'Andrea ' ) ; , PRIMARY KEY ( order_id ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 207 , 'Elise ' , 'Kamenar ' , ' C ' , 'Caswell ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 155 , 274.14 , 151 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 215 , 515.79 , 96 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 22 , 193.12 , 6 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 150 , 'Agnesse ' , 'Liebmann ' , ' B ' , 'Bernard ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 104 , 'Timofei ' , 'Grene ' , ' B ' , 'Armena ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 160 , 144.6 , 82 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 8 , 'Gasparo ' , 'Bohlje ' , ' C ' , 'Abner ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 60 , 473.05 , 208 ) ; def qep_parser ( postgresql : Connection ) : FROM { ORDERS_TABLE_NAME } o2 insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 58 , 'Lettie ' , 'Coffin ' , ' B ' , 'Almena ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 125 , 'Leo ' , 'Creaney ' , ' B ' , 'Augustus ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 190 , 401.19 , 88 ) ; `` `` '' def main ( ) : insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 108 , 294.25 , 131 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 110 , 144.28 , 59 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 144 , 'Ange ' , 'Pasterfield ' , ' C ' , 'Bedelia ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 138 , 'Ainsley ' , 'Wraighte ' , ' C ' , 'Barticus ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 147 , 180.39 , 2 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 58 , 10.24 , 74 ) ; return any ( [ subquery.find ( sqlglot.exp.Order ) for subquery in subqueries ] ) ORDER BY o.customer_id ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 203 , 'Rory ' , 'Hallatt ' , ' C ' , 'Casey ' ) ; print ( `` SQL_WITHOUT_OUTER_ORDER '' ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 216 , 'Elsbeth ' , 'MacGaughie ' , ' B ' , 'Charles ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 149 , 340.62 , 215 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 186 , 'Chloette ' , 'Ratt ' , ' B ' , 'Calpurnia ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 174 , 597.34 , 184 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 184 , 'Louise ' , 'Jansey ' , ' C ' , 'California ' ) ; WHERE c.customer_id = o.customer_id ) FROM { CUSTOMERS_TABLE_NAME } c insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 189 , 'Merle ' , 'Erridge ' , ' C ' , 'Camille ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 2 , 409.8 , 217 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 158 , 65.82 , 201 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 198 , 'Kellby ' , 'Threlfall ' , ' C ' , 'Carolann ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 101 , 328.66 , 189 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 239 , 'Atalanta ' , 'Girdler ' , ' C ' , 'Claire ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 217 , 302.24 , 189 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 230 , 389.39 , 247 ) ; if len ( sys.argv ) ! = 2 : insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 143 , 'Sasha ' , 'Eunson ' , ' C ' , 'Beck ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 235 , 230.72 , 168 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 95 , 367.31 , 48 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 36 , 225.6 , 136 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 208 , 'Legra ' , 'Drought ' , ' C ' , 'Catherine ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 100 , 'Gypsy ' , 'Bottrell ' , ' C ' , 'Aristotle ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 206 , 'Ardyth ' , 'Conningham ' , ' B ' , 'Cassidy ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 94 , 406.59 , 129 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 194 , 'Corilla ' , 'Aldwinckle ' , ' C ' , 'Carmellia ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 81 , 'Sharline ' , 'Rosenwald ' , ' B ' , 'Anna ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 6 , 132.85 , 206 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 235 , 'Justus ' , 'Barthrup ' , ' B ' , 'Christy ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 135 , 574.1 , 222 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 205 , 'Orlan ' , 'Kynder ' , ' C ' , 'Cassandra ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 147 , 'Wilmer ' , 'MacWhan ' , ' B ' , 'Benedict ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 47 , 163.79 , 141 ) ; REFERENCES { CUSTOMERS_TABLE_NAME } ( customer_id ) insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 52 , 81.47 , 212 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 205 , 508.59 , 59 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 5 , 582.52 , 172 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 211 , 'Jobi ' , 'Bails ' , ' B ' , 'Cecilia ' ) ; # everything . This check is left here for documentation of one such case . insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 40 , 'Olva ' , 'Leborgne ' , ' C ' , 'Alexandra ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 114 , 'Fara ' , 'Arkil ' , ' B ' , 'Arzada ' ) ; print ( USAGE , file=sys.stderr ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 149 , 'Erik ' , 'Cushe ' , ' B ' , 'Benjy ' ) ; def _test ( expected : bool , sql_statement : str , db_name : str ) : def test_inner_orderby ( sql_parser : SqlParser , qep_parser : QEPParser ) : insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 64 , 534.3 , 108 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 66 , 'Sadella ' , 'Boxhall ' , ' B ' , 'Alzada ' ) ; f '' '' '' insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 125 , 170.66 , 131 ) ; WHERE c.customer_id = o.customer_id insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 4 , 'Nancey ' , 'Fawlkes ' , ' C ' , 'Abel ' ) ; from pprint import pprint insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 38 , 366.31 , 59 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 72 , 'Nadiya ' , 'Gingles ' , ' B ' , 'Anderson ' ) ; _test ( True , STATEMENT_MULTIPLE_INNER_ORDERS , db_name ) insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 35 , 'Lainey ' , 'Davidow ' , ' C ' , 'Aldrich ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 226 , 'Emelina ' , 'Ayliff ' , ' B ' , 'Chris ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 145 , 112.51 , 162 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 34 , 64.76 , 13 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 20 , 'Robbi ' , ' O '' Caherny ' , ' B ' , 'Adelphia ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 36 , 'Bendite ' , 'Morfett ' , ' B ' , 'Aleksandr ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 73 , 'Seymour ' , 'Maffioletti ' , ' B ' , 'Andre ' ) ; # assert warning_msg is not None insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 16 , 'Augustin ' , 'Blaxall ' , ' C ' , 'Adelaide ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 155 , 'Murdock ' , 'Dix ' , ' C ' , 'Bess ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 207 , 205.25 , 199 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 173 , 297.4 , 85 ) ; load= [ load_database ] , insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 18 , 438.38 , 26 ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 65 , 318.64 , 6 ) ; main ( ) insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 91 , 331.76 , 115 ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 200 , 'Fanni ' , 'Iacopetti ' , ' C ' , 'Carolyn ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 67 , 'Zsazsa ' , 'Bellocht ' , ' C ' , 'Amanda ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 97 , 'Germain ' , 'Haly ' , ' B ' , 'Archilles ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 222 , 'Hazel ' , 'Rushforth ' , ' C ' , 'Chester ' ) ; insert into { ORDERS_TABLE_NAME } ( order_id , order_total_eur , customer_id ) values ( 81 , 490.65 , 41 ) ; return warning_msg insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 218 , 'Raffarty ' , 'Sweeney ' , ' C ' , 'Charlotte ' ) ; SELECT * insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 182 , 'Sasha ' , 'Stiffkins ' , ' C ' , 'Caldonia ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 31 , 'Dario ' , 'Siehard ' , ' C ' , 'Alazama ' ) ; insert into { CUSTOMERS_TABLE_NAME } ( customer_id , fname , sname , type , nickname ) values ( 112 , 'Nanci ' , 'Byrd ' , ' C ' , 'Arthur ' ) ;","['src/pg4n/orderby.py', 'src/pg4n/subquery_orderby_checker.py', 'src/pg4n/test/test_subquery_orderby_checker.py']",2022-11-07 18:54:47+00:00,2022-11-08 08:07:17+00:00,2022-11-08 10:05:35+02:00
70,bbd831ee1f05324f62486eca5ace30ed845111a7,0.0013787038624286,0,,Detect strange HAVING clause without GROUP BY ( e32 per Brass ),Merge pull request # 77 from Project-C-SQL/feat/errfmt,"warning_msg = `` Warning : Possible use of '= ' instead of % for wildcard pattern [ pg4n : :EqWildcard ] '' formatter = ErrorFormatter ( warning , warning_name ) msg_header = f '' Warning : Comparison between different domains ( { domain1 } , { domain2 } ) [ pg4n : :CmpDomains ] \n '' warning_name = `` SumDistinct '' self.warning_msg = self.warning_msg + msg_header + underlined_query formatter = ErrorFormatter ( warning , warning_name ) from . qepparser import QEPAnalysis warning_name = `` EqWildcard '' warning_name = `` SubquerySelect '' ) self.warning_msg = formatter.format ( ) warning_name = `` StrangeHaving '' VT100_RESET = `` \x1b [ 0m '' warning = `` DISTINCT in SUM or AVG '' warning_name = `` CmpDomains '' warning_name = `` SurplusSemicolons '' warning_name = `` InnerOrderBy '' warning = `` ORDER BY in a subquery '' warning_msg = `` Warning : ORDER BY in a subquery [ pg4n : :InnerOrderBy ] '' warning_name = `` ImpliedExpression '' warning_msg = `` Warning : DISTINCT in SUM or AVG [ pg4n : :SumDistinct ] '' self.warning_name : str = warning_name warning_header = `` Warning : No column in subquery SELECT references its tables [ pg4n : :SubquerySelect ] \n '' warning_msg = formatter.format ( ) self.underlined_query : Optional [ str ] = underlined_query warning = `` Too many semicolons '' assert ( warning = `` No column in subquery SELECT references its tables '' formatter = ErrorFormatter ( warning , warning_name , underlined_query ) warning_msg.find ( warning ) ! = -1 self.warning_msg : str = warning_msg warning_msg += formatter.format ( ) warning = `` HAVING without GROUP BY '' from typing import Optional underlined_query : Optional [ str ] = None , assert warning_msg.find ( warning ) ! = -1 and warning_msg.find ( warning_name ) ! = -1 def __init__ ( warning = `` Too many parentheses '' warning_name = `` SurplusParentheses '' from .qepparser import QEPAnalysis FROM customers ) : class ErrorFormatter : and warning_msg.find ( warning_name ) ! = -1 warning = f '' Comparison between different domains ( { domain1 } , { domain2 } ) '' Returns a formatted error message . return base_msg warning = `` Found impossible comparison due to column/table constraints '' def test_format ( ) : self , formatter = ErrorFormatter ( warning , warning_name , underlined_query ) from .errfmt import ErrorFormatter underlined_query = f '' '' '' SELECT * from .. errfmt import ErrorFormatter warning_name : str , base_msg = f '' Warning : { self.warning_msg } [ pg4n : : { self.warning_name } ] '' warning_msg = `` Warning : HAVING without GROUP BY [ pg4n : :StrangeHaving ] '' if self.underlined_query : warning_msg = `` Warning : Found impossible comparison due to column/table constraints [ pg4n : :ImpliedExpression ] '' warning = `` Possible use of '= ' instead of LIKE for wildcard pattern '' def format ( self ) - > str : `` `` '' and warning_msg.find ( underlined_query ) ! = -1 VT100_UNDERLINE = `` \x1b [ 4m '' warning_msg : str , warning_msg += warning_header + underlined_query { VT100_UNDERLINE } WHERE type ' C ' { VT100_RESET } = 1 OR 100 = 100 ; '' '' '' return base_msg + f '' \n { self.underlined_query } '' warning_msg = formatter.format ( )","['src/pg4n/cmp_domain_checker.py', 'src/pg4n/eq_wildcard_checker.py', 'src/pg4n/errfmt.py', 'src/pg4n/implied_expression_checker.py', 'src/pg4n/strange_having_checker.py', 'src/pg4n/subquery_orderby_checker.py', 'src/pg4n/subquery_select_checker.py', 'src/pg4n/sum_distinct_checker.py', 'src/pg4n/test/test_errfmt.py']",2022-11-17 17:50:30+00:00,2022-11-21 10:02:16+00:00,2022-11-21 12:21:55+02:00
79,994c90902cfebc3d5a4f4756e8b07aa1f1899d21,3.2440268114442006e-05,0,"Removing ` \n 's is a tough problem , see ought to replace \n with ` ` to avoid ` SELECT * FROM ` .",Edge cases with newlined psql queries,Merge pull request # 36 from Project-C-SQL/fix/refactor-sqlparser,"assert False , f '' exception : { e } '' from sqlglot.dialects.postgres import Postgres # Patches the postgres dialect to recognize bpchar sql_expression = parse ( statement ) IMPOSSIBLE_STATEMENT = \ try : def parse ( sql : str ) - > sqlglot.exp.Expression : def test_parse_one ( ) : if __name__ == `` __main__ '' : Does not validate that 'sql ' contains only 1 statement ! def test_parse ( ) : class SqlParser : IMPOSSIBLE_STATEMENT = \ def parse_one ( self , sql : str ) - > sqlglot.exp.Expression : pprint ( where_expression ) `` `` '' def parse ( self , sql : str ) - > list [ sqlglot.exp.Expression ] : SELECT * FROM orders Parses the first statement in 'sql ' . parsed = parser.parse_one ( statement ) ) ; '' '' '' return where_statement 'sql ' should be a string of one or more postgresql statements ( delimited by ' ; ' ) . print ( 80 * '= ' ) exit ( 1 ) pprint ( sql_expression ) The last ' ; ' in 'sql ' is optional . parsed = parser.parse ( statement ) [ 0 ] import pytest hype CHAR ( 1 ) CHECK ( hype = ANY ( ARRAY [ ' X ' : :bpchar , ' Y ' : :bpchar ] ) ) 'sql ' should be a postgresql statement . print ( USAGE , file=sys.stderr ) parsed = sqlglot.parse_one ( sql ) self.dialect = `` postgres '' WHERE order_total_eur = 0 AND order_total_eur = 100 ; '' '' '' Throws sqlglot.ParseError on invalid sql . Parses all the statements in 'sql ' . from pprint import pprint parser = sqlparser.SqlParser ( ) except Exception as e : TABLE_NAME = `` orders '' from .. import sqlparser statement = IMPOSSIBLE_STATEMENT where_statement = parsed.find ( sqlglot.exp.Where ) if len ( sys.argv ) ! = 1 : f '' SELECT * FROM { TABLE_NAME } `` \ CHECK_CONSTRAINT = \ statement = IMPOSSIBLE_STATEMENT `` WHERE order_total_eur = 0 AND order_total_eur = 100 ; '' def get_where_expression ( sql : str ) - > str : main ( ) return sqlglot.parse ( sql , read=self.dialect ) The trailing ' ; ' in 'sql ' is optional . where_expression = get_where_expression ( statement ) return sqlglot.parse_one ( sql , read=self.dialect ) def __init__ ( self ) : `` `` '' Postgres.Tokenizer.KEYWORDS [ `` BPCHAR '' ] = sqlglot.TokenType.CHAR def main ( ) : USAGE = `` usage : sql_parser.py '' return sqlglot.parse_one ( sql ) CREATE TABLE dummy ( statement = CHECK_CONSTRAINT","['src/pg4n/sqlparser.py', 'src/pg4n/test/test_sqlparser.py']",2022-11-19 17:10:41+00:00,2022-12-12 12:47:05+00:00,2022-10-26 12:21:19+03:00
91,6c5e663747462817aa670b59addb191b618c5eb9,0.9990333318710328,0,QEPParser executes sql queries prefixed with ` EXPLAIN ANALYZE ` using the psycopg library . The program crashes when psycopg detects sql error and throws an exception that is not caught in QEPParser . Exploration / partial fix in branch tmp/qepparser-crash,Fix QEPParser crashes on sql syntax errors,Merge pull request # 29 from Project-C-SQL/feat/qep-parser,"`` `` '' Represents the result of EXPLAIN ANALYZE . '' '' '' `` Scan Direction '' : str , assert qep.plan [ `` Node Type '' ] == `` Seq Scan '' return QEPNode ( self._node [ `` Plans '' ] [ key ] ) `` Triggers '' : list [ str ] , for copy-and-pasting `` Plans '' : List [ `` node '' ] , create table comments ( node = TypedDict ( `` Plan '' , { assert qep.plan [ `` Actual Rows '' ] == 4 `` Plan Rows '' : int , assert qep.plan [ `` Relation Name '' ] == `` comments '' return self ( stmt , * args , * * kwargs ) `` Parent Relationship '' : str , story_id integer references stories ( id ) on delete cascade , import qepparser conn : connection = psycopg2.connect ( * * kwargs ) * * kwargs : Keyword arguments to pass to cursor.execute ( ) . postgresql_in_docker = factories.postgresql_noproc ( self._ref = not not conn qep = parser ( `` select * from users where id = 1 and id = 2 '' ) def plan ( self ) - > node : assert qep.plan [ `` Relation Name '' ] == `` stories '' raise ValueError ( f '' Expected dict in column , got { t } '' ) # TODO : break into variants discriminated by Node Type return self._node return qepparser.QEPParser ( conn=postgresql ) * text=auto def load_database ( * * kwargs ) : import psycopg2 `` `` '' A dict of the query execution plan 's properties . '' '' '' def __call__ ( self , stmt : str , * args , * * kwargs ) - > QEPAnalysis : return list ( filter ( pred , self._node [ `` Plans '' ] ) ) qep = parser ( `` select * from stories where id = 1 '' ) def __init__ ( self , qep_ : qep ) : return self._node.__str__ ( ) def __init__ ( self , node_ : node ) : qep = parser ( `` select * from stories where id = 1 and id = 2 '' ) return map ( QEPNode , self._node [ `` Plans '' ] ) password=getenv ( `` POSTGRES_PASSWORD '' , `` postgres '' ) ) qep = parser ( `` select * from stories where id = 1 or id = 2 '' ) if ( n : = len ( res [ 0 ] ) ) ! = 1 : self._node = node_ insert into comments ( story_id , user_id , comment ) values ( 2 , 1 , 'comment3 ' ) ; insert into comments ( story_id , user_id , comment ) values ( 1 , 2 , 'comment2 ' ) ; qep = parser ( `` select * from users where id = 1 '' ) def __len__ ( self ) - > int : return self._node [ `` Plans '' ] `` Actual Total Time '' : float , `` `` '' A dict of the root node 's properties . '' '' '' `` `` '' The root node of the query execution plan . '' '' '' qep = parser ( `` select * from users '' ) assert qep.plan [ `` Actual Rows '' ] == 2 `` Filter '' : str , return self._qep.__repr__ ( ) `` `` '' Iterate over child nodes . '' '' '' if ( n : = len ( res [ 0 ] [ 0 ] ) ) ! = 1 : import pytest with self._conn.cursor ( ) as cur : insert into stories ( name ) values ( 'story1 ' ) ; # are available for each node type assert qep.plan [ `` Node Type '' ] == `` Index Scan '' if ( t : = type ( res [ 0 ] [ 0 ] [ 0 ] ) ) ! = dict : if not self._ref : `` Alias '' : str , qep = parser ( `` select * from comments where id = 1 and id = 2 '' ) def plans ( self ) - > list [ node ] : `` Planning Time '' : float , insert into comments ( story_id , user_id , comment ) values ( 1 , 1 , 'comment1 ' ) ; return self._qep def __del__ ( self ) : `` Execution Time '' : float , create table stories ( id serial primary key , name varchar ) ; self._qep = qep_ return QEPNode ( self._qep [ `` Plan '' ] ) assert qep.plan [ `` Relation Name '' ] == `` users '' class QEPAnalysis : qep = TypedDict ( `` QEP '' , { qep = parser ( `` select * from comments '' ) `` `` '' Test that the QEP structure is as expected . '' '' '' self._conn.close ( ) raise ValueError ( f '' Expected 1 row , got { n } '' ) assert qep.root [ 0 ] .plan [ `` Actual Rows '' ] == 0 assert qep.plan [ `` Node Type '' ] == `` Bitmap Heap Scan '' qep = parser ( `` select * from stories '' ) `` `` '' Get the number of child nodes . '' '' '' insert into comments ( story_id , user_id , comment ) values ( 2 , 2 , 'comment4 ' ) ; def parser ( postgresql : connection ) : Executes a query and returns the query execution plan as a dictionary . `` `` '' } ) cur.execute ( `` '' '' drop table if exists users ; return QEPAnalysis ( res [ 0 ] [ 0 ] [ 0 ] ) create table users ( id serial primary key , name varchar ) ; demonstrates relational data assert qep.root [ 0 ] .plan [ `` Alias '' ] == `` users '' Parameters : id serial primary key , def parse ( self , stmt : str , * args , * * kwargs ) - > QEPAnalysis : `` Plan '' : node , from typing import Callable , Iterable , List , TypedDict qep = parser ( `` select * from comments where id = 1 '' ) `` Total Cost '' : float , res = cur.fetchall ( ) `` Index Name '' : str , assert qep.root [ 0 ] .plan [ `` Node Type '' ] == `` Index Scan '' `` `` '' Find nodes matching the predicate . '' '' '' `` Total Runtime '' : float , `` `` '' Get the child node at the given index . '' '' '' def root ( self ) - > QEPNode : return len ( self._node [ `` Plans '' ] ) assert qep.plan [ `` Alias '' ] == `` users '' class QEPParser : def test_qep_structure ( parser : qepparser.QEPParser ) : from os import getenv conn.commit ( ) assert qep.plan [ `` Alias '' ] == `` stories '' cur.execute ( stmt , * args , * * kwargs ) def qep ( self ) - > qep : drop table if exists stories ; comment varchar ) ; insert into users ( name ) values ( 'user1 ' ) ; if ( n : = len ( res ) ) ! = 1 : `` Startup Cost '' : float , '' 'Alias for __call__ '' ' `` Relation Name '' : str , raise ValueError ( f '' Expected 1 item in column , got { n } '' ) return self._qep.__str__ ( ) `` Index Cond '' : str , assert qep.root [ 0 ] .plan [ `` Alias '' ] == `` stories '' def __init__ ( self , * args , conn=None , * * kwargs ) : `` Actual Loops '' : int , self._conn.rollback ( ) # right now , the interface is n't safe to use because it 's not clear what fields def __iter__ ( self ) - > Iterable [ `` QEPNode '' ] : def __str__ ( self ) : stmt = f '' explain ( format json , analyze , verbose ) { stmt.strip ( ) .rstrip ( ' ; ' ) } ; '' A dictionary representing the query execution plan . drop table if exists comments ; `` `` '' A node in a query execution plan . '' '' '' `` `` '' A list of the node 's children . '' '' '' `` `` '' A dict of the node 's properties . '' '' '' with conn.cursor ( ) as cur : `` `` '' ) `` Actual Rows '' : int , populate with sample data assert qep.root [ 0 ] .plan [ `` Alias '' ] == `` comments '' assert qep.root [ 0 ] .plan [ `` Relation Name '' ] == `` stories '' `` `` '' Performs analyses on given queries , returning resultant QEPAnalysis . '' '' '' return self._qep [ `` Plan '' ] qep = parser ( `` select * from users where id = 1 or id = 2 '' ) self._conn : connection = conn or psycopg2.connect ( * args , * * kwargs ) postgresql = factories.postgresql ( `` postgresql_in_docker '' ) stmt : The query to execute . return self._node.__repr__ ( ) insert into stories ( name ) values ( 'story2 ' ) ; from psycopg2.extensions import connection from pytest_postgresql import factories `` Node Type '' : str , assert qep.plan [ `` Alias '' ] == `` comments '' assert qep.plan [ `` Node Type '' ] == `` Result '' Returns : def __repr__ ( self ) : assert qep.root [ 0 ] .plan [ `` Relation Name '' ] == `` users '' load= [ load_database ] , insert into users ( name ) values ( 'user2 ' ) ; def __getitem__ ( self , key : int ) - > `` QEPNode '' : `` Actual Startup Time '' : float , `` Plan Width '' : int , assert qep.plan [ `` Actual Rows '' ] == 1 raise ValueError ( f '' Expected 1 column , got { n } '' ) assert qep.root [ 0 ] .plan [ `` Relation Name '' ] == `` comments '' * args : Positional arguments to pass to cursor.execute ( ) . user=getenv ( `` POSTGRES_USER '' , `` postgres '' ) , class QEPNode : user_id integer references users ( id ) on delete cascade , def find ( self , pred : Callable [ [ node ] , bool ] ) - > list [ node ] :","['.gitattributes', 'qepparser.py', 'test_qepparser.py']",2022-11-25 12:06:28+00:00,2022-12-16 11:05:51+00:00,2022-10-11 17:32:29+03:00
91,994c90902cfebc3d5a4f4756e8b07aa1f1899d21,4.828049350180663e-05,0,QEPParser executes sql queries prefixed with ` EXPLAIN ANALYZE ` using the psycopg library . The program crashes when psycopg detects sql error and throws an exception that is not caught in QEPParser . Exploration / partial fix in branch tmp/qepparser-crash,Fix QEPParser crashes on sql syntax errors,Merge pull request # 36 from Project-C-SQL/fix/refactor-sqlparser,"assert False , f '' exception : { e } '' from sqlglot.dialects.postgres import Postgres # Patches the postgres dialect to recognize bpchar sql_expression = parse ( statement ) IMPOSSIBLE_STATEMENT = \ try : def parse ( sql : str ) - > sqlglot.exp.Expression : def test_parse_one ( ) : if __name__ == `` __main__ '' : Does not validate that 'sql ' contains only 1 statement ! def test_parse ( ) : class SqlParser : IMPOSSIBLE_STATEMENT = \ def parse_one ( self , sql : str ) - > sqlglot.exp.Expression : pprint ( where_expression ) `` `` '' def parse ( self , sql : str ) - > list [ sqlglot.exp.Expression ] : SELECT * FROM orders Parses the first statement in 'sql ' . parsed = parser.parse_one ( statement ) ) ; '' '' '' return where_statement 'sql ' should be a string of one or more postgresql statements ( delimited by ' ; ' ) . print ( 80 * '= ' ) exit ( 1 ) pprint ( sql_expression ) The last ' ; ' in 'sql ' is optional . parsed = parser.parse ( statement ) [ 0 ] import pytest hype CHAR ( 1 ) CHECK ( hype = ANY ( ARRAY [ ' X ' : :bpchar , ' Y ' : :bpchar ] ) ) 'sql ' should be a postgresql statement . print ( USAGE , file=sys.stderr ) parsed = sqlglot.parse_one ( sql ) self.dialect = `` postgres '' WHERE order_total_eur = 0 AND order_total_eur = 100 ; '' '' '' Throws sqlglot.ParseError on invalid sql . Parses all the statements in 'sql ' . from pprint import pprint parser = sqlparser.SqlParser ( ) except Exception as e : TABLE_NAME = `` orders '' from .. import sqlparser statement = IMPOSSIBLE_STATEMENT where_statement = parsed.find ( sqlglot.exp.Where ) if len ( sys.argv ) ! = 1 : f '' SELECT * FROM { TABLE_NAME } `` \ CHECK_CONSTRAINT = \ statement = IMPOSSIBLE_STATEMENT `` WHERE order_total_eur = 0 AND order_total_eur = 100 ; '' def get_where_expression ( sql : str ) - > str : main ( ) return sqlglot.parse ( sql , read=self.dialect ) The trailing ' ; ' in 'sql ' is optional . where_expression = get_where_expression ( statement ) return sqlglot.parse_one ( sql , read=self.dialect ) def __init__ ( self ) : `` `` '' Postgres.Tokenizer.KEYWORDS [ `` BPCHAR '' ] = sqlglot.TokenType.CHAR def main ( ) : USAGE = `` usage : sql_parser.py '' return sqlglot.parse_one ( sql ) CREATE TABLE dummy ( statement = CHECK_CONSTRAINT","['src/pg4n/sqlparser.py', 'src/pg4n/test/test_sqlparser.py']",2022-11-25 12:06:28+00:00,2022-12-16 11:05:51+00:00,2022-10-26 12:21:19+03:00
